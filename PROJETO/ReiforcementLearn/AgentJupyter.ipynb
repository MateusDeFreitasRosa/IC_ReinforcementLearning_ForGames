{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d443a7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ana\\envs\\ReinforcementLearningOldVersion\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ana\\envs\\ReinforcementLearningOldVersion\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ana\\envs\\ReinforcementLearningOldVersion\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ana\\envs\\ReinforcementLearningOldVersion\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ana\\envs\\ReinforcementLearningOldVersion\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ana\\envs\\ReinforcementLearningOldVersion\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d2e3219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from plan_experiments import experiment_params\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a0b3211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrindo imagens\n",
    "env = gym.make('Pong-v0')\n",
    "\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65e9e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(state):\n",
    "    %pylab inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.axis(\"off\")\n",
    "    imgplot = plt.imshow(state)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "471ba25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def to_gray_scale(state):\n",
    "    return 0.299*state[:,:,0] + 0.587*state[:,:,1] + 0.114*state[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19e59891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d6b36ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_on_top                =              35\n",
    "crop_on_bottom             =              16\n",
    "crop_on_left               =              7\n",
    "crop_on_right              =              7\n",
    "\n",
    "def crop_img(img):\n",
    "        #return img[self.crop_on_top: -self.crop_on_bottom, self.crop_on_border:-self.crop_on_border]\n",
    "        return img[crop_on_top:-crop_on_bottom, crop_on_left:-crop_on_right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12d4447c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                 Type         Data/Info\n",
      "-----------------------------------------------\n",
      "Adam                     type         <class 'keras.optimizers.Adam'>\n",
      "Conv2D                   type         <class 'keras.layers.convolutional.Conv2D'>\n",
      "Dense                    type         <class 'keras.layers.core.Dense'>\n",
      "Flatten                  type         <class 'keras.layers.core.Flatten'>\n",
      "MaxPooling2D             type         <class 'keras.layers.pooling.MaxPooling2D'>\n",
      "Sequential               type         <class 'keras.engine.sequential.Sequential'>\n",
      "build_model              function     <function build_model at 0x0000011ACB7C80D0>\n",
      "crop_img                 function     <function crop_img at 0x0000011ACC9EB400>\n",
      "crop_on_bottom           int          16\n",
      "crop_on_left             int          7\n",
      "crop_on_right            int          7\n",
      "crop_on_top              int          35\n",
      "cv2                      module       <module 'cv2' from 'C:\\\\a<...>kages\\\\cv2\\\\__init__.py'>\n",
      "deque                    type         <class 'collections.deque'>\n",
      "env                      TimeLimit    <TimeLimit<AtariEnv<Pong-v0>>>\n",
      "experiment_params        dict         n=14\n",
      "grayscale                ndarray      80x80: 6400 elems, type `float64`, 51200 bytes\n",
      "grayscale_new            ndarray      80x80: 6400 elems, type `float64`, 51200 bytes\n",
      "grayscale_old            ndarray      80x80: 6400 elems, type `float64`, 51200 bytes\n",
      "gym                      module       <module 'gym' from 'C:\\\\a<...>kages\\\\gym\\\\__init__.py'>\n",
      "huber_loss               function     <function huber_loss at 0x0000011ACBA48268>\n",
      "huber_loss_mean          function     <function huber_loss_mean at 0x0000011ACB7C8AE8>\n",
      "i                        int          9999\n",
      "memory                   deque        deque([(array([[0.4196078<...>84]]), 1)], maxlen=10000)\n",
      "np                       module       <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "pack_K_frames            function     <function pack_K_frames at 0x0000011ACBA481E0>\n",
      "plt                      module       <module 'matplotlib.pyplo<...>\\\\matplotlib\\\\pyplot.py'>\n",
      "preprocess_img           function     <function preprocess_img at 0x0000011ACB5FB268>\n",
      "preprocess_img_with_cv   function     <function preprocess_img_<...>cv at 0x0000011ACB5FB0D0>\n",
      "processed_img            ndarray      80x80: 6400 elems, type `float64`, 51200 bytes\n",
      "random                   module       <module 'random' from 'C:<...>Version\\\\lib\\\\random.py'>\n",
      "remember                 function     <function remember at 0x0000011ACBA48378>\n",
      "replay                   function     <function replay at 0x0000011ACBA48400>\n",
      "rgb2gray                 function     <function rgb2gray at 0x0000011ACC9EB510>\n",
      "show_image               function     <function show_image at 0x0000011ACC9EB2F0>\n",
      "state                    ndarray      210x160x3: 100800 elems, type `uint8`, 100800 bytes (98.4375 kb)\n",
      "tf                       module       <module 'tensorflow' from<...>tensorflow\\\\__init__.py'>\n",
      "time                     module       <module 'time' (built-in)>\n",
      "to_gray_scale            function     <function to_gray_scale at 0x0000011ACA86DA60>\n"
     ]
    }
   ],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cd4cb6",
   "metadata": {},
   "source": [
    "## Testando duas maneiras de pr√©-processamento de imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9c3d29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORST WAY\n",
    "\n",
    "def preprocess_img(img):        \n",
    "        return to_gray_scale(cv2.resize(crop_img(img), (80,80), interpolation=cv2.INTER_AREA)) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e230edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BEST WAY !!!\n",
    "\n",
    "def preprocess_img_with_cv(img):\n",
    "    return np.divide(cv2.cvtColor(cv2.resize(crop_img(state) , (80,80), interpolation=cv2.INTER_AREA), cv2.COLOR_RGB2GRAY ), 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a40d894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9469354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale_old = preprocess_img(state)\n",
    "grayscale_new = preprocess_img_with_cv(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3312487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11acbc05358>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(grayscale_new, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed084df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11acc288748>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(grayscale_old, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30decd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Testando a maneira que estamos aplicando a IC.\n",
    "\n",
    "for i in range(10000):\n",
    "    grayscale = preprocess_img(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "08b91e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10000):\n",
    "    grayscale = preprocess_img_with_cv(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e3d798",
   "metadata": {},
   "source": [
    "## Tentativa de otimiza√ß√£o no processo de treinamento da rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06693a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importa√ß√µes necess√°rias\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from plan_experiments import experiment_params\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e4c08650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install GPU version of TF\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceb47686",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-659b71ab71e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Num GPUs Available: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GPU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'config'"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2bbae071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss(y_true, y_pred, clip_delta=1.0):\n",
    "    error = y_true - y_pred\n",
    "    cond  = tf.keras.backend.abs(error) < clip_delta\n",
    "\n",
    "    squared_loss = 0.5 * tf.keras.backend.square(error)\n",
    "    linear_loss  = clip_delta * (tf.keras.backend.abs(error) - 0.5 * clip_delta)\n",
    "\n",
    "    return tf.where(cond, squared_loss, linear_loss)\n",
    "\n",
    "'''\n",
    " ' Same as above but returns the mean loss.\n",
    "'''\n",
    "def huber_loss_mean(y_true, y_pred, clip_delta=1.0):\n",
    "    return tf.keras.backend.mean(huber_loss(y_true, y_pred, clip_delta))\n",
    "\n",
    "def build_model():\n",
    "        \n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "\n",
    "\n",
    "        ## Create structure of convolucional network.\n",
    "        structure_convolucional = experiment_params['structure_neural_network']['conv']\n",
    "\n",
    "        for conv in structure_convolucional:\n",
    "            model.add(Conv2D(conv['filter'], conv['kernel_size'], strides=conv['strides'],  input_shape = (80, 80, 4),\n",
    "                             activation=conv['activation'], padding=conv['padding']))\n",
    "\n",
    "        model.add(Flatten()) # Transform image resulting of convolution to 1 dimension\n",
    "\n",
    "        ## Create structure of neural network.\n",
    "        structure_nn = experiment_params['structure_neural_network']['neural_network']\n",
    "\n",
    "        for nn in structure_nn:\n",
    "            k_init = nn['kernel_initializer'] if 'kernel_initializer' in nn else 'glorot_uniform'\n",
    "            model.add(Dense(nn['neurons'], activation=nn['activation'], kernel_initializer=k_init))\n",
    "\n",
    "        model.add(Dense(4, activation='linear'))\n",
    "        model.compile(loss=huber_loss_mean, optimizer=Adam(lr=.0001))\n",
    "\n",
    "        model.summary()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2186023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def pack_K_frames(sample_batch_size):\n",
    "        \n",
    "        state = np.empty((sample_batch_size, 4, 80, 80))\n",
    "        action = np.empty(sample_batch_size, dtype=np.uint8)\n",
    "        reward = np.empty(sample_batch_size, dtype=np.float32)\n",
    "        next_state = np.empty((sample_batch_size, 4, 80, 80))\n",
    "        done = np.empty(sample_batch_size, dtype=bool)\n",
    "        \n",
    "\n",
    "        for k in range(sample_batch_size):\n",
    "            index = random.randint(0, len(memory)-4-2)\n",
    "            \n",
    "            for i, idx_memory in enumerate(range(index, index+4)):\n",
    "                s, a, r, n_s, d = memory[idx_memory]\n",
    "            \n",
    "                state[k][i] = s\n",
    "                next_state[k][i] = n_s\n",
    "                \n",
    "            done[k] = d\n",
    "            action[k] = a\n",
    "            reward[k] = r\n",
    "            \n",
    "        #State = (32,4,84,84)  -> State Transpose = (32,84,84,4) \n",
    "        return np.transpose(state, axes=(0,2,3,1)), action, reward, np.transpose(next_state, axes=(0,2,3,1)), done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e67436f9",
   "metadata": {},
   "outputs": [],
   "source": [
    " def replay(sample_batch_size):\n",
    "    \n",
    "    soma = 0\n",
    "    t = time.time()\n",
    "    #sample_batch = random.sample(self.memory, sample_batch_size)\n",
    "    state, action, reward, next_state, done = pack_K_frames(sample_batch_size)\n",
    "    time_pack_K_frames = time.time() - t\n",
    "    t = time.time()\n",
    "    \n",
    "    t = time.time()\n",
    "    with tf.device('/gpu:0'):\n",
    "        predicted = brain_target.predict(next_state) #Previs√£o proximo estado.\n",
    "    time_predicted = time.time() - t\n",
    "    t = time.time()\n",
    "    with tf.device('/gpu:0'):\n",
    "        target_f = brain.predict(state) #Previs√£o estado atual.\n",
    "    time_target_f = time.time() - t\n",
    "    t = time.time()\n",
    "        \n",
    "    for i in range(sample_batch_size):\n",
    "        target = reward[i] + (.99 * np.amax(predicted[i]) * (1-done[i]))\n",
    "        target_f[i][action[i]] = target\n",
    "    \n",
    "    time_calc = time.time() - t\n",
    "    t = time.time()\n",
    "    \n",
    "    with tf.device('/gpu:0'):\n",
    "        brain.fit(state, target_f, batch_size=sample_batch_size, epochs=1, verbose=0, shuffle=False)\n",
    "    time_fit = time.time() - t\n",
    "    \n",
    "    soma = (time_predicted + time_calc + time_fit + time_target_f + time_pack_K_frames)\n",
    "    time_predicted = (time_predicted / soma)*100\n",
    "    time_target_f = (time_target_f / soma)*100\n",
    "    time_calc = (time_calc / soma)*100\n",
    "    time_fit = (time_fit / soma)*100\n",
    "    time_pack_K_frames = (time_pack_K_frames / soma)*100\n",
    "    \n",
    "#     print('K_frames: {}\\nPredicted: {}\\nTarget_F: {}\\nCalc: {}\\nFit: {}'.format(time_pack_K_frames, \n",
    "#                                                                                 time_predicted, \n",
    "#                                                                                 time_target_f, \n",
    "#                                                                                 time_calc, \n",
    "#                                                                                 time_fit))\n",
    "    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "14edf99c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_46 (Conv2D)           (None, 19, 19, 32)        8224      \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 8, 8, 64)          32832     \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 1,406,180\n",
      "Trainable params: 1,406,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_49 (Conv2D)           (None, 19, 19, 32)        8224      \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 8, 8, 64)          32832     \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 1,406,180\n",
      "Trainable params: 1,406,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Wall time: 922 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "def remember(state, action, reward, next_state, done):        \n",
    "    memory.append((processed_img, action, reward, processed_img, done))\n",
    "\n",
    "    \n",
    "    \n",
    "memory = deque(maxlen=1000000)\n",
    "processed_img = preprocess_img_with_cv(state)\n",
    "    \n",
    "## Carregamento de mem√≥ria apenas para test.\n",
    "for i in range(2000000):\n",
    "    remember(processed_img, 1, 1, processed_img, 1)\n",
    "\n",
    "brain = build_model()\n",
    "brain_target = build_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6a34afd0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "replay(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7a00fdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(50):\n",
    "    replay(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2166cd7d",
   "metadata": {},
   "source": [
    "### Verificar gasto de mem√≥ria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5eb474e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a65aebe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d_16/kernel:0' shape=(8, 8, 4, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_16/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_17/kernel:0' shape=(4, 4, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_17/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_18/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_18/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_21/kernel:0' shape=(2304, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_21/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_22/kernel:0' shape=(512, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_22/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_23/kernel:0' shape=(256, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_23/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_24/kernel:0' shape=(64, 4) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_24/bias:0' shape=(4,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "018dd339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8057.2578125"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(memory) / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "34e7ec5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(brain.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4099abbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36686.8515625"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = 1832294\n",
    "(((8*params) / 1024) * 2) + (sys.getsizeof(memory) / 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "06c7e83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30030.8515625"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = 1406310\n",
    "(((8*params) / 1024) * 2) + (sys.getsizeof(memory) / 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3adf8093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1efbab",
   "metadata": {},
   "source": [
    "##### Tempos de execu√ß√£o:\n",
    "\n",
    "- 2,81\n",
    "- 2,54\n",
    "- 2,57\n",
    "- 2,59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea42955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Mar 26 10:10:11 2020\n",
    "\n",
    "@author: mateu\n",
    "\"\"\"\n",
    "\n",
    "import gym\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "import imageio\n",
    "from plan_experiments import experiment_params\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "\n",
    "######################################################################################################################################\n",
    "#import tensorflow as tf\n",
    "#import keras.backend.tensorflow_backend as tfback\n",
    "\n",
    "#print(\"tf.__version__ is\", tf.__version__)\n",
    "#print(\"tf.keras.__version__ is:\", tf.keras.__version__)\n",
    "\n",
    "#def _get_available_gpus():\n",
    "#    \"\"\"Get a list of available gpu devices (formatted as strings).\n",
    "#\n",
    "#    # Returns\n",
    "#        A list of available GPU devices.\n",
    "#   \"\"\"\n",
    "    #global _LOCAL_DEVICES\n",
    "#    if tfback._LOCAL_DEVICES is None:\n",
    "#        devices = tf.config.list_logical_devices()\n",
    "#        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
    "#    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
    "\n",
    "#print(_get_available_gpus())\n",
    "#tfback._get_available_gpus = _get_available_gpus\n",
    "\n",
    "####VERIFY IF GPU IS RUNNING.\n",
    "#print(device_lib.list_local_devices())\n",
    "#from keras import backend as K\n",
    "#K.tensorflow_backend._get_available_gpus()\n",
    "#import keras\n",
    "\n",
    "#import tensorflow.compat.v1 as tf1\n",
    "\n",
    "'''\n",
    "config = tf1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 4} ) \n",
    "sess = tf1.Session(config=config) \n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "'''\n",
    "\n",
    "######################################################################################################################################\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "'''\n",
    " ' Huber loss.\n",
    " ' https://jaromiru.com/2017/05/27/on-using-huber-loss-in-deep-q-learning/\n",
    " ' https://en.wikipedia.org/wiki/Huber_loss\n",
    "'''\n",
    "def huber_loss(y_true, y_pred, clip_delta=1.0):\n",
    "  error = y_true - y_pred\n",
    "  cond  = tf.keras.backend.abs(error) < clip_delta\n",
    "\n",
    "  squared_loss = 0.5 * tf.keras.backend.square(error)\n",
    "  linear_loss  = clip_delta * (tf.keras.backend.abs(error) - 0.5 * clip_delta)\n",
    "\n",
    "  return tf.where(cond, squared_loss, linear_loss)\n",
    "\n",
    "'''\n",
    " ' Same as above but returns the mean loss.\n",
    "'''\n",
    "def huber_loss_mean(y_true, y_pred, clip_delta=1.0):\n",
    "  return tf.keras.backend.mean(huber_loss(y_true, y_pred, clip_delta))\n",
    "\n",
    "score = []\n",
    "\n",
    "TRAIN = True\n",
    "OBSERVER = 100\n",
    "UPDATE_TARGET_MODEL = experiment_params['freq_update_nn']\n",
    "qntUpdate=0\n",
    "tamMemoryK = 100 # O tamanho da memoria ser√° esse valor multiplicado por 1000.\n",
    "\n",
    "game = experiment_params['game']\n",
    "total_reward_game = []\n",
    "\n",
    "\n",
    "## List to save in dataframe.\n",
    "reward_current_episode = []\n",
    "train_current_episode = []\n",
    "current_time_episode = []\n",
    "average_loss = []\n",
    "average_fps_current_episode = []\n",
    "current_exploration = []\n",
    "\n",
    "resultado = []\n",
    "\n",
    "class Agent(): \n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.weight_backup              =       experiment_params['dirs']['dir_model']+experiment_params['game']+\".h5\"\n",
    "        self.state_size                 =       state_size\n",
    "        self.action_size                =       action_size\n",
    "        self.memory                     =       deque(maxlen=experiment_params['params_agent']['memory_size']) if TRAIN else deque(maxlen=5)\n",
    "        self.learning_rate              =       experiment_params['params_agent']['learning_rate']\n",
    "        self.gamma                      =       experiment_params['params_agent']['gamma']\n",
    "        self.exploration_rate           =       experiment_params['params_agent']['exploration_rate']\n",
    "        self.exploration_min            =       experiment_params['params_agent']['exploration_min']\n",
    "        self.exploration_decay          =       experiment_params['params_agent']['exploration_decay']\n",
    "        self.k_frames                   =       experiment_params['params_agent']['k_frames']\n",
    "        self.frame_height               =       self.state_size[0]\n",
    "        self.frame_width                =       self.state_size[1]\n",
    "        self.brain                      =       self._build_model()\n",
    "        self.brain_target               =       self._build_model()\n",
    "        self.freq_update_nn             =       experiment_params['freq_update_nn']\n",
    "\n",
    "\n",
    "    def _build_model(self):\n",
    "        #with tf.device('/gpu:0'):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "            \n",
    "        \n",
    "        ## Create structure of convolucional network.\n",
    "        structure_convolucional = experiment_params['structure_neural_network']['conv']\n",
    "        \n",
    "        for conv in structure_convolucional:\n",
    "            model.add(Conv2D(conv['filter'], conv['kernel_size'], strides=conv['strides'],  input_shape = (self.state_size[0], self.state_size[1], self.k_frames),\n",
    "                             activation=conv['activation'], padding=conv['padding']))\n",
    "        \n",
    "        model.add(Flatten()) # Transform image resulting of convolution to 1 dimension\n",
    "        \n",
    "        ## Create structure of neural network.\n",
    "        structure_nn = experiment_params['structure_neural_network']['neural_network']\n",
    "        \n",
    "        for nn in structure_nn:\n",
    "            k_init = nn['kernel_initializer'] if 'kernel_initializer' in nn else 'glorot_uniform'\n",
    "            model.add(Dense(nn['neurons'], activation=nn['activation'], kernel_initializer=k_init))\n",
    "            \n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss=huber_loss_mean, optimizer=Adam(learning_rate=self.learning_rate))\n",
    "            \n",
    "        model.summary()\n",
    "        if self.has_load_data():\n",
    "            model.load_weights(self.weight_backup)\n",
    "            self.exploration_rate = self.exploration_min\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def has_load_data(self):\n",
    "        global data_average_reward, total_reward_game, trainsPerEpisode\n",
    "        if os.path.isfile(self.weight_backup):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def save_model(self):\n",
    "        self.brain.save(self.weight_backup)\n",
    "        \n",
    "            \n",
    "    def get_last_k_frames(self, state):\n",
    "        frames = np.empty((self.k_frames, self.frame_height, self.frame_width))\n",
    "\n",
    "        for i in range(0, self.k_frames):\n",
    "            _, _, _, n_s, _ = self.memory[len(self.memory)-(self.k_frames-i)]\n",
    "            frames[i] = n_s\n",
    "            \n",
    "        return np.transpose(frames, axes=(1,2,0))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.exploration_rate or len(self.memory) < self.k_frames+1:\n",
    "            return random.randrange(self.action_size)\n",
    "        \n",
    "        k_frames_state = self.get_last_k_frames(state)\n",
    "        k_frames_state = np.expand_dims(k_frames_state, axis=0)\n",
    "        act_values = self.brain.predict(k_frames_state)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):        \n",
    "        self.memory.append((state, action, reward, next_state, done))      \n",
    "\n",
    "\n",
    "    def pack_K_frames(self, sample_batch_size):\n",
    "        global resultado\n",
    "        if len(self.memory) < self.k_frames+2:\n",
    "            return\n",
    "        \n",
    "        state = np.empty((sample_batch_size, self.k_frames, self.frame_height, self.frame_width))\n",
    "        action = np.empty(sample_batch_size, dtype=np.uint8)\n",
    "        reward = np.empty(sample_batch_size, dtype=np.float32)\n",
    "        next_state = np.empty((sample_batch_size, self.k_frames, self.frame_height, self.frame_width))\n",
    "        done = np.empty(sample_batch_size, dtype=np.bool)\n",
    "        \n",
    "\n",
    "        for k in range(sample_batch_size):\n",
    "            index = random.randint(0, len(self.memory)-self.k_frames-2)\n",
    "            \n",
    "            for i, idx_memory in enumerate(range(index, index+self.k_frames)):\n",
    "                s, a, r, n_s, d = self.memory[idx_memory]\n",
    "            \n",
    "                state[k][i] = s\n",
    "                next_state[k][i] = n_s\n",
    "                \n",
    "            done[k] = d\n",
    "            action[k] = a\n",
    "            reward[k] = r\n",
    "            \n",
    "           \n",
    "        #State = (32,4,84,84)  -> State Transpose = (32,84,84,4) \n",
    "        return np.transpose(state, axes=(0,2,3,1)), action, reward, np.transpose(next_state, axes=(0,2,3,1)), done\n",
    "        \n",
    "\n",
    "    def replay(self, sample_batch_size):\n",
    "       \n",
    "        if len(self.memory) < sample_batch_size:\n",
    "            return\n",
    "        \n",
    "        #sample_batch = random.sample(self.memory, sample_batch_size)\n",
    "        state, action, reward, next_state, done = self.pack_K_frames(sample_batch_size)\n",
    "        \n",
    "        #print('State: {}'.format(state.shape))\n",
    "        #print('Action: {}'.format(action.shape))\n",
    "        #print('Reward: {}'.format(reward.shape))\n",
    "        #print('Next_State: {}'.format(next_state.shape))\n",
    "        #print('Done: {}'.format(done.shape))\n",
    "        #input()\n",
    "        #target = reward\n",
    "        predicted = self.brain_target.predict(next_state) #Previs√£o proximo estado.\n",
    "        target_f = self.brain.predict(state) #Previs√£o estado atual.\n",
    "        #print('Predicted: {}'.format(predicted))\n",
    "        #print('Predicted[0]: {}'.format(predicted[2]))\n",
    "        #print('Predicted Max: {}'.format(np.amax(predicted)))\n",
    "        #print('Reward: {}'.format(reward))\n",
    "        #print('Target_f: {}'.format(target_f))\n",
    "        #input()\n",
    "        \n",
    "        for i in range(sample_batch_size):\n",
    "            target = reward[i] + (self.gamma * np.amax(predicted[i]) * (1-done[i]))\n",
    "            target_f[i][action[i]] = target\n",
    "            #print('Action: {}'.format(action[i]))\n",
    "            #print('target: {}'.format(target))\n",
    "            #print('target_f: {}'.format(target_f[i]))\n",
    "            #input()\n",
    "            \n",
    "        \n",
    "        #print('Target_f Formatado: {}'.format(target_f))\n",
    "        #input()\n",
    "        history = self.brain.fit(state, target_f, batch_size=sample_batch_size, epochs=1, verbose=0)\n",
    "            \n",
    "        if self.exploration_rate > self.exploration_min:\n",
    "            self.exploration_rate -= self.exploration_decay\n",
    "    \n",
    "        return history, self.exploration_rate\n",
    "\n",
    "    def update_target_model(self, current_frame):\n",
    "        if (current_frame % UPDATE_TARGET_MODEL == 0 and TRAIN and current_frame > OBSERVER):\n",
    "            self.brain_target.set_weights(self.brain.get_weights())\n",
    "            global qntUpdate\n",
    "            qntUpdate+=1\n",
    "            print('-------------------------UPDATED TARGET MODEL({}) ------------------------------'.format(qntUpdate))\n",
    "\n",
    "\n",
    "class Breakout():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.env = gym.make(game)\n",
    "        self.sample_batch_size          =              experiment_params['sample_batch_size']\n",
    "        self.episodes                   =              experiment_params['episodes']\n",
    "        self.action_size                =              self.env.action_space.n\n",
    "        self.state_size                 =              experiment_params['structure_neural_network']['input_shape']\n",
    "        self.agent                      =              Agent(self.state_size, self.action_size)\n",
    "        self.number_print               =              0\n",
    "        self.best_score                 =              -99999999\n",
    "        self.replay_bestPlay            =              deque(maxlen=300)\n",
    "        self.crop_on_top                =              experiment_params['prune_image']['top']\n",
    "        self.crop_on_bottom             =              experiment_params['prune_image']['bottom'] \n",
    "        self.crop_on_left               =              experiment_params['prune_image']['left']\n",
    "        self.crop_on_right              =              experiment_params['prune_image']['right']\n",
    "        self.frames_skip                =              experiment_params['frames_skip']\n",
    "        self.current_frame              =              0\n",
    "        self.freq_update                =              experiment_params['freq_update_nn']\n",
    "        self.down_sample_of             =              experiment_params['down_sample']\n",
    "        self.canSave                    =              True\n",
    "        self.time_train_init            =              time.time()\n",
    "        self.epochs_to_save_results     =              experiment_params['epochs_to_save_results']\n",
    "        self.frames_in_atual_episode    =              0\n",
    "        self.seconds_in_atual_episode   =              0\n",
    "        \n",
    "        self.initialize_dirs() # If not exist the dirs, this function create.\n",
    "    \n",
    "  \n",
    "    def initialize_dirs(self):\n",
    "        for keys, values in experiment_params['dirs'].items():\n",
    "            \n",
    "            if not os.path.isdir(values):\n",
    "                os.makedirs(values)\n",
    "        \n",
    "    def reset_results(self):\n",
    "        global reward_current_episode, train_current_episode, current_time_episode, average_loss, \\\n",
    "        average_fps_current_episode, current_exploration\n",
    "        \n",
    "        reward_current_episode = []\n",
    "        train_current_episode = []\n",
    "        current_time_episode = []\n",
    "        average_loss = []\n",
    "        average_fps_current_episode = []\n",
    "        current_exploration = []\n",
    "        \n",
    "        \n",
    "    def add_new_result(self, reward, train, time, loss, exploration, fps):\n",
    "        \n",
    "        global reward_current_episode, train_current_episode, current_time_episode, average_loss,  \\\n",
    "        average_fps_current_episode, current_exploration\n",
    "        \n",
    "        reward_current_episode.append(reward)\n",
    "        train_current_episode.append(train)\n",
    "        current_time_episode.append(time)\n",
    "        average_loss.append(loss),\n",
    "        current_exploration.append(exploration)\n",
    "        average_fps_current_episode.append(fps)\n",
    "\n",
    "        \n",
    "        if len(reward_current_episode) >= self.epochs_to_save_results:\n",
    "            print('Saving dataframe results...')\n",
    "            self.save_results()\n",
    "        \n",
    "        \n",
    "    def save_results(self):\n",
    "       global reward_current_episode, train_current_episode, current_time_episode, average_loss, \\\n",
    "       average_fps_current_episode, current_exploration\n",
    "              \n",
    "      \n",
    "       if len(reward_current_episode) <= 0:\n",
    "           return\n",
    "       \n",
    "       df_results = pd.DataFrame({\n",
    "           'REWARD': reward_current_episode,\n",
    "           'TRAIN': train_current_episode,\n",
    "           'TIME': current_time_episode,\n",
    "           'LOSS': average_loss,\n",
    "           'EXPLORATION_RATE': current_exploration,\n",
    "           'FPS': average_fps_current_episode\n",
    "       })\n",
    "       \n",
    "       df_backup = pd.DataFrame()\n",
    "       if os.path.isfile(experiment_params['dirs']['dir_results']+'df_results.csv'):\n",
    "           df_backup = pd.read_csv(experiment_params['dirs']['dir_results']+'df_results.csv')\n",
    "           df_results = pd.concat([df_backup, df_results])\n",
    "           \n",
    "       df_results.to_csv(experiment_params['dirs']['dir_results']+'df_results.csv', index=False)\n",
    "       \n",
    "       self.reset_results()\n",
    "       \n",
    "       \n",
    "    def save_params(self):\n",
    "        with open(experiment_params['dir_annotations_experiments']+'annotations.md', 'w') as f:\n",
    "            f.write(experiment_params)\n",
    "\n",
    "   \n",
    "    def restart_chronometer(self):\n",
    "        self.frames_in_atual_episode=0\n",
    "        self.seconds_in_atual_episode=0\n",
    "    \n",
    "    def get_frames_per_seconds_in_atual_episode(self):\n",
    "        return int(self.frames_in_atual_episode / (time.time() - self.seconds_in_atual_episode))\n",
    "    \n",
    "    def to_gray_scale(self, img):\n",
    "        return 0.299*img[:,:,0] + 0.587*img[:,:,1] + 0.114*img[:,:,2]\n",
    "    \n",
    "    def down_sample(self, img):\n",
    "        return img[::self.down_sample_of,::self.down_sample_of]\n",
    "    \n",
    "    def preprocess_img(self, img):        \n",
    "        new_image = cv2.resize(np.asarray(self.to_gray_scale(self.crop_img(img)) / 255, dtype=np.float32), self.state_size, interpolation=cv2.INTER_AREA)\n",
    "        '''plt.imshow(new_image)\n",
    "        plt.show()\n",
    "        print('Shape: {}'.format(new_image.shape))\n",
    "        input()'''\n",
    "        return new_image\n",
    "        \n",
    "    def crop_img(self, img):\n",
    "        #return img[self.crop_on_top: -self.crop_on_bottom, self.crop_on_border:-self.crop_on_border]\n",
    "        return img[self.crop_on_top:-self.crop_on_bottom, self.crop_on_left:-self.crop_on_right]\n",
    "  \n",
    "    def transform_reward(self, reward):\n",
    "        return np.sign(reward)\n",
    "      \n",
    "    def formatTimeBr(time):\n",
    "        horas = time/3600\n",
    "        minutos = (time%3600)/60\n",
    "        segundos = (time%3600)%60\n",
    "        \n",
    "        return str('{}hr : {}min : {}seg'.format(horas, minutos, segundos))\n",
    "    \n",
    "    def save_image_epoch(self, gif_to_save, epoch, best_current_play=False):\n",
    "        \n",
    "        if best_current_play:\n",
    "            epoch = str(epoch)+'_best'\n",
    "        else:\n",
    "            epoch = str(epoch)\n",
    "        \n",
    "        if (self.canSave and len(gif_to_save) > 0):\n",
    "    \n",
    "            imageio.mimwrite(experiment_params['dirs']['dir_videos']+epoch+'.mp4', gif_to_save , fps = 100)\n",
    "            print('Gif Salvo') \n",
    "            self.canSave = False\n",
    "            \n",
    "            \n",
    "    def run(self):\n",
    "        global total_reward_game\n",
    "\n",
    "        try:\n",
    "            for i_episodes in range(self.episodes):\n",
    "                state = self.env.reset()\n",
    "               \n",
    "                state = self.preprocess_img(state)\n",
    "                \n",
    "                done = False\n",
    "                current_images_episode = []\n",
    "                \n",
    "                total_reward=0\n",
    "                history_list = []\n",
    "                exploration = 1.0\n",
    "                self.seconds_in_atual_episode= time.time()\n",
    "                \n",
    "                while not done:\n",
    "                                        \n",
    "                    #if i_episodes > 600 or not TRAIN:\n",
    "                    #self.env.render()\n",
    "                    action = self.agent.act(state)\n",
    "                    next_state, reward, done, info = self.env.step(action)\n",
    "                    \n",
    "                    reward = np.sign(reward)\n",
    "                    total_reward+=reward\n",
    "           \n",
    "                    next_state = self.preprocess_img(next_state)\n",
    "                    \n",
    "                    current_images_episode.append(next_state)\n",
    "                    \n",
    "                    self.agent.remember(state, action, reward, next_state, done)\n",
    "                    state = next_state\n",
    "                        \n",
    "                    self.current_frame+=1\n",
    "                    self.frames_in_atual_episode+=1\n",
    "                    if TRAIN:\n",
    "                        if self.current_frame > OBSERVER and (self.current_frame % self.frames_skip) == 0:\n",
    "                            history, exploration = self.agent.replay(self.sample_batch_size)\n",
    "                            history_list.append(history.history['loss'])    \n",
    "                        \n",
    "                        self.agent.update_target_model(self.current_frame)\n",
    "    \n",
    "                total_reward_game.append(total_reward)\n",
    "                \n",
    "                \n",
    "                if TRAIN and self.current_frame > OBSERVER:\n",
    "                    if i_episodes % 2 == 0:\n",
    "                        self.canSave=True\n",
    "                        \n",
    "                        self.save_image_epoch( current_images_episode, i_episodes)   \n",
    "                    \n",
    "                    self.add_new_result(total_reward, (self.current_frame / self.frames_skip), time.time(), \n",
    "                                        np.mean(history_list), exploration, self.get_frames_per_seconds_in_atual_episode())\n",
    "                   \n",
    "                    if total_reward > self.best_score and self.current_frame > OBSERVER:\n",
    "                            self.best_score = total_reward\n",
    "                            self.agent.save_model()\n",
    "                            self.save_image_epoch(current_images_episode, i_episodes, best_current_play=True)\n",
    "                            print('Save best current model -> ', end='')\n",
    "                current_images_episode = []\n",
    "                print(\"Episode {}# r: {}# Loss: {:.6} # Train: {} # eps: {:.3}# Space: {}% 'fps: {}:\".format(i_episodes, total_reward, np.mean(history_list), (self.current_frame / self.frames_skip), exploration, round(((len(self.agent.memory) / (tamMemoryK*1000)) * 100), 2), self.get_frames_per_seconds_in_atual_episode() ))\n",
    "                self.restart_chronometer()\n",
    "        finally:\n",
    "            if TRAIN:\n",
    "                self.agent.save_model()\n",
    "                self.save_results()\n",
    "                \n",
    "                \n",
    "            self.env.close()\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    breakout = Breakout()\n",
    "    breakout.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0210c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
