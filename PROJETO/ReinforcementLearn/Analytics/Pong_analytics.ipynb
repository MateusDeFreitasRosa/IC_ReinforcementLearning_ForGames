{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eab63d31",
   "metadata": {},
   "source": [
    "# Análise dos dados obtidos no jogo Pong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef72ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\ana\\envs\\reinforcementlearningoldversion\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\ana\\envs\\reinforcementlearningoldversion\\lib\\site-packages (from seaborn) (3.3.4)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\mateus f\\appdata\\roaming\\python\\python36\\site-packages (from seaborn) (1.19.5)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\ana\\envs\\reinforcementlearningoldversion\\lib\\site-packages (from seaborn) (1.1.5)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\ana\\envs\\reinforcementlearningoldversion\\lib\\site-packages (from seaborn) (1.5.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\ana\\envs\\reinforcementlearningoldversion\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\ana\\envs\\reinforcementlearningoldversion\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\ana\\envs\\reinforcementlearningoldversion\\lib\\site-packages (from matplotlib>=2.2->seaborn) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\ana\\envs\\reinforcementlearningoldversion\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\ana\\envs\\reinforcementlearningoldversion\\lib\\site-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\ana\\envs\\reinforcementlearningoldversion\\lib\\site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mateus f\\appdata\\roaming\\python\\python36\\site-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd5a5b7",
   "metadata": {},
   "source": [
    "## Definições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90cca1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dfs = 'df_results.csv'\n",
    "name_dict_experiments = 'plan_experiments.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d43f2fe",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb0216d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4edc8e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_documents(uri):\n",
    "    \n",
    "    '''\n",
    "        uri: (str) Diretório onde se encontra o experimento que deseja ser lido.\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv(uri+name_dfs)\n",
    "    js = json.load(open(uri+name_dict_experiments))\n",
    "    \n",
    "    return (df, js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33629acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(jsn, tab=0, specific_key=None):\n",
    "    \n",
    "    '''\n",
    "        jsn: (dict) Dicionário contendo os parâmetros do experimento.\n",
    "        tab: (int) Esse parâmetro é para realizar a identação da visualização criada. Não é necessário modifica-lo.\n",
    "        specific_key: (list) Como nossos parâmetros são compostos por map dentro de map, ou melhor, dict dentro de dict, é \n",
    "                        possível especificar um parâmetro específico do dicionário de experimento.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if specific_key != None and isinstance(specific_key, list):\n",
    "        for sk in specific_key:\n",
    "            if sk in jsn:\n",
    "                jsn = jsn[sk] if isinstance(jsn[sk], dict) else {\n",
    "                    sk: jsn[sk]\n",
    "                }\n",
    "            else:\n",
    "                print('Não existe essa key: {}'.format(sk))\n",
    "            \n",
    "    for k, v in jsn.items():\n",
    "        if isinstance(v, dict):\n",
    "            print('\\n - {}'.format(k))\n",
    "            summary(v, tab+1)\n",
    "        elif isinstance(v, list):\n",
    "            if len(v) > 0 and isinstance(v[0], dict):\n",
    "                print('\\n - {}:'.format(k))\n",
    "                for enum, vi in enumerate(v, 1):\n",
    "                    print('\\n{} > {}({}):'.format('\\t'*tab, k, enum))\n",
    "                    summary(vi, tab+1)\n",
    "            else:\n",
    "                print('{}{}: {}'.format('\\t'*tab, k, v))\n",
    "        else:\n",
    "            print('{}{}: {}'.format('\\t'*tab, k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9766c5",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f906c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(446, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pong, dict_pong = get_documents('../experiments/Pong/')\n",
    "df_pong.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cbb0d2",
   "metadata": {},
   "source": [
    "#### Informações sobre o experimento 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c9df28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: 0.0.0\n",
      "game: Pong-v0\n",
      "description: \n",
      "    \n",
      "    ..\n",
      "    \n",
      "    \n",
      "sample_batch_size: 32\n",
      "epochs_to_save_results: 10\n",
      "freq_update_nn: 1000\n",
      "frames_skip: 1\n",
      "down_sample: 2\n",
      "episodes: 10000\n",
      "freq_save_video: 10\n",
      "\n",
      " - dirs\n",
      "\tdir_results: experiments/Pong/\n",
      "\tdir_annotations_experiments: experiments/Pong/\n",
      "\tdir_videos: experiments/Pong/movies/\n",
      "\tdir_model: experiments/Pong/model/\n",
      "\n",
      " - prune_image\n",
      "\ttop: 35\n",
      "\tbottom: 16\n",
      "\tright: 7\n",
      "\tleft: 7\n",
      "\n",
      " - params_agent\n",
      "\tmemory_size: 150000\n",
      "\tmin_learning_rate: 8e-05\n",
      "\tmax_learning_rate: 8e-05\n",
      "\tepochs_interval_lr: 0\n",
      "\tgamma: 0.99\n",
      "\texploration_rate: 1\n",
      "\texploration_min: 0.05\n",
      "\texploration_decay: 1e-05\n",
      "\tk_frames: 4\n",
      "\n",
      " - structure_neural_network\n",
      "\tinput_shape: [80, 80]\n",
      "\toutput_activation: linear\n",
      "\n",
      " - conv:\n",
      "\n",
      "\t > conv(1):\n",
      "\t\tfilter: 32\n",
      "\t\tkernel_size: [8, 8]\n",
      "\t\tstrides: 4\n",
      "\t\tactivation: relu\n",
      "\t\tpadding: valid\n",
      "\n",
      "\t > conv(2):\n",
      "\t\tfilter: 64\n",
      "\t\tkernel_size: [4, 4]\n",
      "\t\tstrides: 2\n",
      "\t\tactivation: relu\n",
      "\t\tpadding: valid\n",
      "\n",
      "\t > conv(3):\n",
      "\t\tfilter: 64\n",
      "\t\tkernel_size: [3, 3]\n",
      "\t\tstrides: 1\n",
      "\t\tactivation: relu\n",
      "\t\tpadding: valid\n",
      "\n",
      " - neural_network:\n",
      "\n",
      "\t > neural_network(1):\n",
      "\t\tneurons: 512\n",
      "\t\tactivation: relu\n",
      "\n",
      "\t > neural_network(2):\n",
      "\t\tneurons: 256\n",
      "\t\tactivation: relu\n",
      "\t\tkernel_initializer: he_uniform\n",
      "\n",
      "\t > neural_network(3):\n",
      "\t\tneurons: 64\n",
      "\t\tactivation: relu\n",
      "\t\tkernel_initializer: he_uniform\n"
     ]
    }
   ],
   "source": [
    "summary(dict_pong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df6fa2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pong_v1, dict_pong_v1 = get_documents('../experiments/Pong-v1/')\n",
    "df_pong_v1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e3261d",
   "metadata": {},
   "source": [
    "#### Informações sobre o experimento 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "333bfdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: 0.0.1\n",
      "game: Pong-v0\n",
      "description: \n",
      "    \n",
      "    Experimento variando o learning rate de ( 0.00009 ) até ( 0.000005 ) em 200 episódios.\n",
      "    A ideia é observar se o agente obtém um melhor desempenho, conseguindo atingir melhores pontuações do meio para o fim do experimento.\n",
      "    \n",
      "    \n",
      "sample_batch_size: 32\n",
      "epochs_to_save_results: 10\n",
      "freq_update_nn: 1000\n",
      "frames_skip: 1\n",
      "down_sample: 2\n",
      "episodes: 10000\n",
      "freq_save_video: 10\n",
      "\n",
      " - dirs\n",
      "\tdir_results: experiments/Pong-v1/\n",
      "\tdir_annotations_experiments: experiments/Pong-v1/\n",
      "\tdir_videos: experiments/Pong-v1/movies/\n",
      "\tdir_model: experiments/Pong-v1/model/\n",
      "\n",
      " - prune_image\n",
      "\ttop: 35\n",
      "\tbottom: 16\n",
      "\tright: 7\n",
      "\tleft: 7\n",
      "\n",
      " - params_agent\n",
      "\tmemory_size: 150000\n",
      "\tmin_learning_rate: 5e-06\n",
      "\tmax_learning_rate: 9e-05\n",
      "\tepochs_interval_lr: 200\n",
      "\tgamma: 0.99\n",
      "\texploration_rate: 1\n",
      "\texploration_min: 0.05\n",
      "\texploration_decay: 1e-05\n",
      "\tk_frames: 4\n",
      "\n",
      " - structure_neural_network\n",
      "\tinput_shape: [80, 80]\n",
      "\toutput_activation: linear\n",
      "\n",
      " - conv:\n",
      "\n",
      "\t > conv(1):\n",
      "\t\tfilter: 32\n",
      "\t\tkernel_size: [8, 8]\n",
      "\t\tstrides: 4\n",
      "\t\tactivation: relu\n",
      "\t\tpadding: valid\n",
      "\n",
      "\t > conv(2):\n",
      "\t\tfilter: 64\n",
      "\t\tkernel_size: [4, 4]\n",
      "\t\tstrides: 2\n",
      "\t\tactivation: relu\n",
      "\t\tpadding: valid\n",
      "\n",
      "\t > conv(3):\n",
      "\t\tfilter: 64\n",
      "\t\tkernel_size: [3, 3]\n",
      "\t\tstrides: 1\n",
      "\t\tactivation: relu\n",
      "\t\tpadding: valid\n",
      "\n",
      " - neural_network:\n",
      "\n",
      "\t > neural_network(1):\n",
      "\t\tneurons: 512\n",
      "\t\tactivation: relu\n",
      "\n",
      "\t > neural_network(2):\n",
      "\t\tneurons: 256\n",
      "\t\tactivation: relu\n",
      "\t\tkernel_initializer: he_uniform\n",
      "\n",
      "\t > neural_network(3):\n",
      "\t\tneurons: 64\n",
      "\t\tactivation: relu\n",
      "\t\tkernel_initializer: he_uniform\n"
     ]
    }
   ],
   "source": [
    "summary(dict_pong_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88188818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1403, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pong_v5, dict_pong_v5 = get_documents('../experiments/Pong-v5/')\n",
    "df_pong_v5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed72c46",
   "metadata": {},
   "source": [
    "#### Informações sobre o experimento 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab4ba9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: 0.0.1\n",
      "game: Pong-v0\n",
      "description: \n",
      "    \n",
      "    Experimento variando o learning rate de ( 0.00009 ) até ( 0.000005 ) em 200 episódios.\n",
      "    A ideia é observar se o agente obtém um melhor desempenho, conseguindo atingir melhores pontuações do meio para o fim do experimento.\n",
      "    \n",
      "    \n",
      "sample_batch_size: 32\n",
      "epochs_to_save_results: 10\n",
      "freq_update_nn: 1000\n",
      "frames_skip: 1\n",
      "down_sample: 2\n",
      "episodes: 10000\n",
      "freq_save_video: 10\n",
      "\n",
      " - dirs\n",
      "\tdir_results: experiments/Pong-v5/\n",
      "\tdir_annotations_experiments: experiments/Pong-v5/\n",
      "\tdir_videos: experiments/Pong-v5/movies/\n",
      "\tdir_model: experiments/Pong-v5/model/\n",
      "\n",
      " - prune_image\n",
      "\ttop: 35\n",
      "\tbottom: 15\n",
      "\tright: 7\n",
      "\tleft: 7\n",
      "\n",
      " - params_agent\n",
      "\tmemory_size: 100000\n",
      "\tmin_learning_rate: 0.0001\n",
      "\tmax_learning_rate: 0.0001\n",
      "\tepochs_interval_lr: 0\n",
      "\tgamma: 0.99\n",
      "\texploration_rate: 1\n",
      "\texploration_min: 0.05\n",
      "\texploration_decay: 1e-05\n",
      "\tk_frames: 4\n",
      "\n",
      " - structure_neural_network\n",
      "\tinput_shape: [84, 84]\n",
      "\toutput_activation: linear\n",
      "\n",
      " - conv:\n",
      "\n",
      "\t > conv(1):\n",
      "\t\tfilter: 32\n",
      "\t\tkernel_size: [8, 8]\n",
      "\t\tstrides: 4\n",
      "\t\tactivation: relu\n",
      "\t\tpadding: valid\n",
      "\n",
      "\t > conv(2):\n",
      "\t\tfilter: 64\n",
      "\t\tkernel_size: [4, 4]\n",
      "\t\tstrides: 2\n",
      "\t\tactivation: relu\n",
      "\t\tpadding: valid\n",
      "\n",
      "\t > conv(3):\n",
      "\t\tfilter: 64\n",
      "\t\tkernel_size: [3, 3]\n",
      "\t\tstrides: 1\n",
      "\t\tactivation: relu\n",
      "\t\tpadding: valid\n",
      "\n",
      " - neural_network:\n",
      "\n",
      "\t > neural_network(1):\n",
      "\t\tneurons: 512\n",
      "\t\tactivation: relu\n",
      "\n",
      "\t > neural_network(2):\n",
      "\t\tneurons: 256\n",
      "\t\tactivation: relu\n",
      "\t\tkernel_initializer: he_uniform\n",
      "\n",
      "\t > neural_network(3):\n",
      "\t\tneurons: 64\n",
      "\t\tactivation: relu\n",
      "\t\tkernel_initializer: he_uniform\n"
     ]
    }
   ],
   "source": [
    "summary(dict_pong_v5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a70a60",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032a1090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(n):\n",
    "    return 0 if n<0 else n\n",
    "    \n",
    "def mean_reward(values, interval):\n",
    "    \n",
    "    '''\n",
    "        Essa função tem como propósito melhorar a visualização das recompensas ao longo dos jogos.\n",
    "        Ela remove o ruído da visualização realizando a média de cada ponto considerando a uma quantidade de valores.\n",
    "        \n",
    "        \n",
    "        values: (list) Valores que serão aplicado a média.\n",
    "        interval: (int) Quantidade de valores que serão considerados para os cálculos das médias.\n",
    "    '''\n",
    "    \n",
    "    mean_rewards = []\n",
    "    \n",
    "    for i in range(1, len(values)+1):\n",
    "        #print('{} - {} ||| len: {}'.format(norm(i-interval), i, len(values[norm(i-interval):i])))\n",
    "        mean_rewards.append(values[norm(i-interval):i].mean())\n",
    "\n",
    "    return mean_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bcfa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pong['MEAN_REWARD'] = mean_reward(df_pong['REWARD'], 50)\n",
    "df_pong_v1['MEAN_REWARD'] = mean_reward(df_pong_v1['REWARD'], 50)\n",
    "df_pong_v5['MEAN_REWARD'] = mean_reward(df_pong_v5['REWARD'], 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79658369",
   "metadata": {},
   "source": [
    "### Estrutura dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2af996",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(dict_pong, specific_key=['structure_neural_network'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a63a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(dict_pong_v1, specific_key=['structure_neural_network'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e54ff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(dict_pong_v5, specific_key=['structure_neural_network'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad483820",
   "metadata": {},
   "source": [
    "## Visualizações "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad75fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, sharex=True, sharey=True, figsize=(15, 10))\n",
    "fig.suptitle('Visualizações ')\n",
    "axs[0].plot(df_pong['TRAIN'], df_pong['MEAN_REWARD'])\n",
    "axs[1].plot(df_pong_v1['TRAIN'], df_pong_v1['MEAN_REWARD'])\n",
    "axs[2].plot(df_pong_v5['TRAIN'], df_pong_v5['MEAN_REWARD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb151a5",
   "metadata": {},
   "source": [
    "## Comparação de experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d6276",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(df_pong['TRAIN'], df_pong['MEAN_REWARD'], label='Experimento (0)')\n",
    "plt.plot(df_pong_v1['TRAIN'], df_pong_v1['MEAN_REWARD'], label='Experimento (1)')\n",
    "plt.plot(df_pong_v5['TRAIN'], df_pong_v5['MEAN_REWARD'], label='Experimento (5)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dcc15e",
   "metadata": {},
   "source": [
    "> É perceptível que o experimento 5 obteve atingiu melhores resultados com maior rapidez comparado aos outros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a8683b",
   "metadata": {},
   "source": [
    "### Observação da variação da taxa de aprendizado de cada experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44a8c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(df_pong['TRAIN'], df_pong['LR'], label='Experimento (0)')\n",
    "plt.plot(df_pong_v1['TRAIN'], df_pong_v1['LR'], label='Experimento (1)')\n",
    "plt.plot(df_pong_v5['TRAIN'], df_pong_v5['LR'], label='Experimento (5)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90ff1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab3700d",
   "metadata": {},
   "source": [
    "> De acordo com esse gráfico é possível perceber que o experimento 5 obteve resultados melhores com maior rapidez, pois ele estava com uma taxa de aprendizado maior que a dos outros e, não variou, se manteve com 0.0001 do inicio ao fim do treinamento. \n",
    "\n",
    "> Visto isso, é possivel tentar novos experimentos com uma taxa de aprendizado maior, para observar se obtém melhores resultados.\n",
    "\n",
    "**O Trabalho conta com poucos experimentos por questão de tempo, estes levam dias para serem concluídos!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c695e68",
   "metadata": {},
   "source": [
    "### Observação da variação da taxa de exploração de cada experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a24fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(df_pong['TRAIN'], df_pong['EXPLORATION_RATE'], label='Experimento (0)')\n",
    "plt.plot(df_pong_v1['TRAIN'], df_pong_v1['EXPLORATION_RATE'], label='Experimento (1)')\n",
    "plt.plot(df_pong_v5['TRAIN'], df_pong_v5['EXPLORATION_RATE'], label='Experimento (5)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51a1149",
   "metadata": {},
   "source": [
    "> Nos experimentos realizados com o jogo Pong, não foi modificado o decaimento da exploração, todos os 3 experimentos foram realizados seguindo o mesmo modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef094c6",
   "metadata": {},
   "source": [
    "## Tempo gasto para o treinamento de cada experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1949d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_time(sec, label):\n",
    "    minutes = sec//60\n",
    "    sec = int(sec%60)\n",
    "    \n",
    "    hours = minutes//60\n",
    "    minutes %= 60\n",
    "    \n",
    "    days = hours//24\n",
    "    hours %=24\n",
    "    \n",
    "    print('{} - {} dias - {}:{}:{}'.format(label, days, hours, minutes, sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67868fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_0 = df_pong['TIME'].iloc[-1] - df_pong['TIME'].iloc[0]\n",
    "time_1 = df_pong_v1['TIME'].iloc[-1] - df_pong_v1['TIME'].iloc[0]\n",
    "time_5 = df_pong_v5['TIME'].iloc[-1] - df_pong_v5['TIME'].iloc[0]\n",
    "\n",
    "transform_time(time_0, 'Experimento 0')\n",
    "transform_time(time_1, 'Experimento 1')\n",
    "transform_time(time_5, 'Experimento 5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
