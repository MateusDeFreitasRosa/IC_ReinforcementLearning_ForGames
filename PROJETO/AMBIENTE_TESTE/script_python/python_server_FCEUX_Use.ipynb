{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_server_FCEUX import Server\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting connection from emulator...\n",
      "Connected:  <socket.socket fd=1216, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 12345), raddr=('127.0.0.1', 58603)>\n"
     ]
    }
   ],
   "source": [
    "server = Server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonsMode(string):\n",
    "    a = string.decode()\n",
    "    return json.loads(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Get pixeis image.\n",
    "params: {(int) down_sample -> 1, (int) len_max_x -> 255, (int) len_max_y -> 239, (int) len_min_x -> 1,\n",
    "(int) len_min_x -> 1, (bool) grayscale -> False}\n",
    "\n",
    "'''\n",
    "image = server.sendCommandAndReceiveOperation(json.dumps({'operation': 'getScreenShot',\n",
    "          'params': {\n",
    "              'grayscale': True,\n",
    "              'down_sample': 4,\n",
    "              'len_min_y': 45,\n",
    "              'len_max_y': 230\n",
    "          }\n",
    "      }))\n",
    "print('LenImage: {}'.format(len(image)))\n",
    "print(image)\n",
    "#printImage(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = image.decode()\n",
    "b = a.split('json')[1]\n",
    "c = json.loads(b)\n",
    "d = c['matriz']\n",
    "e = np.asarray(d, dtype=np.int16)\n",
    "plt.imshow(e, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Press Joypad\n",
    "'''\n",
    "import time\n",
    "import random\n",
    "begin = time.time()\n",
    "images = []\n",
    "i = 0\n",
    "while True:\n",
    "    try:\n",
    "        print(\"I: {}\".format(i))\n",
    "        data = server.step('right', grayscale=True, downsample=2, min_y=45, max_y=230)\n",
    "        js = jsonsMode(data)\n",
    "        d = js['matriz']\n",
    "        e = np.asarray(d, dtype=np.int16)\n",
    "        if js['endgame'] != 8:\n",
    "            print('END')\n",
    "            server.reset('Super_Mario_Bros.fc1', grayscale=True, downsample=2, min_y=45, max_y=230)\n",
    "        i+=1\n",
    "    except Exception as e:\n",
    "        print('Except: {}'.format(e))\n",
    "        break\n",
    "    \n",
    "end = time.time()\n",
    "print(end - begin)\n",
    "print('I: {}'.format(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseAction(number):\n",
    "    return ['down', 'left', 'right', 'A', 'B'][number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-fdec08ff8e92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mjs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjsonsMode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'matriz'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-d75f850db66d>\u001b[0m in \u001b[0;36mjsonsMode\u001b[1;34m(string)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mjsonsMode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "js = jsonsMode(data)\n",
    "d = js['matriz']\n",
    "e = np.asarray(d, dtype=np.int16)\n",
    "plt.imshow(e, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requisitando novamente timed out\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    op = server.step('right', grayscale=True, downsample=4, min_y=45, max_y=230)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.__version__ is 2.1.0\n",
      "tf.keras.__version__ is: 2.2.4-tf\n",
      "['/device:GPU:0']\n",
      "Waiting connection from emulator...\n",
      "Connected:  <socket.socket fd=3872, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 12345), raddr=('127.0.0.1', 50758)>\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 19, 19, 32)        8224      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 64)          32832     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 1,259,683\n",
      "Trainable params: 1,259,683\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "LastRewards: [174, 179, 180, 177, 178, 389, 178, 356, 176, 177, 179, 399, 178, 410, 476, 406, 162, 168, 165, 178, 392, 178, 186, 177, 425, 192, 185, 480, 110, 381, 176, 490, 349, 461, 455, 164, 461, 378, 433, 424, 524, 201, 195, 183, 474, 168, 185, 501, 427, 171, 176, 384, 192, 408, 390, 302, 386, 253, 501, 183, 170, 484, 184, 477, 182, 192, 442, 197, 403, 179, 409, 397, 432, 181, 183, 183, 178, 183, 404, 425, 410, 427, 524, 188, 294, 184, 289, 183, 301, 188, 536, 466, 403, 446, 511, 537, 167, 193, 419, 136, 468, 406, 449, 428, 195, 406, 423, 418, 196, 509, 184, 174, 490, 183, 172, 399, 374, 417, 381, 499, 432, 512, 266, 487, 518, 453, 454, 405, 383, 175]\n",
      "Average: [174.0, 176.5, 177.66666666666666, 177.5, 177.6, 212.83333333333334, 207.85714285714286, 226.375, 220.77777777777777, 216.4, 213.0, 228.5, 224.6153846153846, 237.85714285714286, 253.73333333333332, 263.25, 257.29411764705884, 252.33333333333334, 247.73684210526315, 244.25, 251.28571428571428, 247.95454545454547, 245.2608695652174, 242.41666666666666, 249.72, 247.5, 245.1851851851852, 253.57142857142858, 248.6206896551724, 253.03333333333333, 250.5483870967742, 258.03125, 260.7878787878788, 266.6764705882353, 272.0571428571429, 269.05555555555554, 274.2432432432432, 276.9736842105263, 280.97435897435895, 284.55, 290.390243902439, 288.26190476190476, 286.09302325581393, 283.75, 287.97777777777776, 285.3695652173913, 283.2340425531915, 287.7708333333333, 290.61224489795916, 288.22, 288.26, 292.36, 292.6, 297.22, 301.46, 299.72, 303.88, 301.82, 308.32, 308.44, 308.26, 309.96, 310.08, 311.42, 305.54, 301.26, 306.86, 307.44, 312.2, 312.22, 312.56, 316.94, 321.86, 321.94, 317.1, 316.92, 316.78, 310.84, 316.72, 317.6, 322.28, 321.02, 324.52, 319.06, 315.84, 316.24, 312.8, 308.9, 306.26, 301.54, 301.78, 307.08, 311.24, 316.5, 317.24, 324.62, 324.26, 318.1, 317.94, 317.24, 323.08, 323.52, 328.66, 329.06, 325.16, 327.24, 327.98, 331.28, 325.18, 331.7, 331.98, 325.78, 331.9, 326.02, 325.82, 329.96, 328.6, 333.0, 332.56, 338.96, 339.42, 341.72, 338.4, 344.52, 351.22, 356.62, 362.14, 366.58, 366.16, 361.16]\n",
      "\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 19, 19, 32)        8224      \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 64)          32832     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 1,259,683\n",
      "Trainable params: 1,259,683\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "LastRewards: [174, 179, 180, 177, 178, 389, 178, 356, 176, 177, 179, 399, 178, 410, 476, 406, 162, 168, 165, 178, 392, 178, 186, 177, 425, 192, 185, 480, 110, 381, 176, 490, 349, 461, 455, 164, 461, 378, 433, 424, 524, 201, 195, 183, 474, 168, 185, 501, 427, 171, 176, 384, 192, 408, 390, 302, 386, 253, 501, 183, 170, 484, 184, 477, 182, 192, 442, 197, 403, 179, 409, 397, 432, 181, 183, 183, 178, 183, 404, 425, 410, 427, 524, 188, 294, 184, 289, 183, 301, 188, 536, 466, 403, 446, 511, 537, 167, 193, 419, 136, 468, 406, 449, 428, 195, 406, 423, 418, 196, 509, 184, 174, 490, 183, 172, 399, 374, 417, 381, 499, 432, 512, 266, 487, 518, 453, 454, 405, 383, 175]\n",
      "Average: [174.0, 176.5, 177.66666666666666, 177.5, 177.6, 212.83333333333334, 207.85714285714286, 226.375, 220.77777777777777, 216.4, 213.0, 228.5, 224.6153846153846, 237.85714285714286, 253.73333333333332, 263.25, 257.29411764705884, 252.33333333333334, 247.73684210526315, 244.25, 251.28571428571428, 247.95454545454547, 245.2608695652174, 242.41666666666666, 249.72, 247.5, 245.1851851851852, 253.57142857142858, 248.6206896551724, 253.03333333333333, 250.5483870967742, 258.03125, 260.7878787878788, 266.6764705882353, 272.0571428571429, 269.05555555555554, 274.2432432432432, 276.9736842105263, 280.97435897435895, 284.55, 290.390243902439, 288.26190476190476, 286.09302325581393, 283.75, 287.97777777777776, 285.3695652173913, 283.2340425531915, 287.7708333333333, 290.61224489795916, 288.22, 288.26, 292.36, 292.6, 297.22, 301.46, 299.72, 303.88, 301.82, 308.32, 308.44, 308.26, 309.96, 310.08, 311.42, 305.54, 301.26, 306.86, 307.44, 312.2, 312.22, 312.56, 316.94, 321.86, 321.94, 317.1, 316.92, 316.78, 310.84, 316.72, 317.6, 322.28, 321.02, 324.52, 319.06, 315.84, 316.24, 312.8, 308.9, 306.26, 301.54, 301.78, 307.08, 311.24, 316.5, 317.24, 324.62, 324.26, 318.1, 317.94, 317.24, 323.08, 323.52, 328.66, 329.06, 325.16, 327.24, 327.98, 331.28, 325.18, 331.7, 331.98, 325.78, 331.9, 326.02, 325.82, 329.96, 328.6, 333.0, 332.56, 338.96, 339.42, 341.72, 338.4, 344.52, 351.22, 356.62, 362.14, 366.58, 366.16, 361.16]\n",
      "\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d_7/convolution (defined at C:\\Users\\mateu\\AppData\\Local\\Continuum\\anaconda3\\envs\\MachineLearning01\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_894]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b37609b53331>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[0mnintendo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNintendo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m     \u001b[0mnintendo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-b37609b53331>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m                     \u001b[1;31m#if i_episodes > 600 or not TRAIN:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                     \u001b[1;31m#self.env.render()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m                     \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m                     \u001b[0mjs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m230\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m                     \u001b[0mnext_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'matriz'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-b37609b53331>\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mk_frames_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_last_k_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mk_frames_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_frames_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         \u001b[0mact_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_frames_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mact_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\MachineLearning01\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1462\u001b[1;33m                                             callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\MachineLearning01\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\MachineLearning01\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\MachineLearning01\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\MachineLearning01\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\MachineLearning01\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\MachineLearning01\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\MachineLearning01\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\MachineLearning01\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv2d_7/convolution (defined at C:\\Users\\mateu\\AppData\\Local\\Continuum\\anaconda3\\envs\\MachineLearning01\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_894]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Mar 26 10:10:11 2020\n",
    "\n",
    "@author: mateu\n",
    "\"\"\"\n",
    "\n",
    "import gym\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "import imageio\n",
    "from python_server_FCEUX import Server\n",
    "\n",
    "\n",
    "######################################################################################################################################\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as tfback\n",
    "\n",
    "print(\"tf.__version__ is\", tf.__version__)\n",
    "print(\"tf.keras.__version__ is:\", tf.keras.__version__)\n",
    "\n",
    "def _get_available_gpus():\n",
    "    \"\"\"Get a list of available gpu devices (formatted as strings).\n",
    "\n",
    "    # Returns\n",
    "        A list of available GPU devices.\n",
    "    \"\"\"\n",
    "    #global _LOCAL_DEVICES\n",
    "    if tfback._LOCAL_DEVICES is None:\n",
    "        devices = tf.config.list_logical_devices()\n",
    "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
    "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
    "\n",
    "print(_get_available_gpus())\n",
    "tfback._get_available_gpus = _get_available_gpus\n",
    "\n",
    "####VERIFY IF GPU IS RUNNING.\n",
    "#print(device_lib.list_local_devices())\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "import keras\n",
    "\n",
    "import tensorflow.compat.v1 as tf1\n",
    "\n",
    "'''\n",
    "config = tf1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 4} ) \n",
    "sess = tf1.Session(config=config) \n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "'''\n",
    "\n",
    "######################################################################################################################################\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "'''\n",
    " ' Huber loss.\n",
    " ' https://jaromiru.com/2017/05/27/on-using-huber-loss-in-deep-q-learning/\n",
    " ' https://en.wikipedia.org/wiki/Huber_loss\n",
    "'''\n",
    "def huber_loss(y_true, y_pred, clip_delta=1.0):\n",
    "  error = y_true - y_pred\n",
    "  cond  = tf.keras.backend.abs(error) < clip_delta\n",
    "\n",
    "  squared_loss = 0.5 * tf.keras.backend.square(error)\n",
    "  linear_loss  = clip_delta * (tf.keras.backend.abs(error) - 0.5 * clip_delta)\n",
    "\n",
    "  return tf.where(cond, squared_loss, linear_loss)\n",
    "\n",
    "'''\n",
    " ' Same as above but returns the mean loss.\n",
    "'''\n",
    "def huber_loss_mean(y_true, y_pred, clip_delta=1.0):\n",
    "  return tf.keras.backend.mean(huber_loss(y_true, y_pred, clip_delta))\n",
    "\n",
    "score = []\n",
    "\n",
    "TRAIN = True\n",
    "OBSERVER = 100\n",
    "UPDATE_TARGET_MODEL = 1000\n",
    "qntUpdate=0\n",
    "tamMemoryK = 150 # O tamanho da memoria será esse valor multiplicado por 1000.\n",
    "\n",
    "game = 'SuperMarioBross'\n",
    "diretorioInProcess = \"./currentProcessICMinih/\"+game+\"/\"\n",
    "total_reward_game = []\n",
    "data_average_reward = []\n",
    "trainsPerEpisode = []\n",
    "\n",
    "class Agent(): \n",
    "    def __init__(self, state_size, action_size,):\n",
    "        self.weight_backup      = diretorioInProcess+game+\".h5\"\n",
    "        self.state_size         = state_size\n",
    "        self.action_size        = action_size\n",
    "        self.memory             = deque(maxlen=tamMemoryK*1000) if TRAIN else deque(maxlen=5)\n",
    "        self.learning_rate      = 0.0005\n",
    "        self.gamma              = 0.97\n",
    "        self.exploration_rate   = .4\n",
    "        self.exploration_min    = 0.05\n",
    "        self.exploration_decay  = 1.0e-5\n",
    "        self.k_frames           = 4\n",
    "        self.frame_height       = self.state_size[0]\n",
    "        self.frame_width        = self.state_size[1]\n",
    "        self.brain              = self._build_model()\n",
    "        self.brain_target       = self._build_model()\n",
    "\n",
    "\n",
    "    def _build_model(self):\n",
    "        with tf.device('/gpu:0'):\n",
    "            # Neural Net for Deep-Q learning Model\n",
    "            model = Sequential()\n",
    "                \n",
    "            #Criar camada de convolução.\n",
    "            #-> (32,84,84,4)\n",
    "            model.add(Conv2D(32, (8,8), strides=4,  input_shape = (self.state_size[0], self.state_size[1], self.k_frames) , activation = 'relu', padding='valid'))\n",
    "            #<- (84,84)\n",
    "            #->(84,84)\n",
    "            #model.add(MaxPooling2D(pool_size = (2,2), dim_ordering='th'))\n",
    "            #<-(42,42)\n",
    "            #->(42,42)\n",
    "            model.add(Conv2D(64, (4,4), strides=2, activation = 'relu', padding='valid'))\n",
    "            #<-(42,42)\n",
    "            #->(42,42)\n",
    "            #model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "            #<-(21,21)\n",
    "            #->(21,21)\n",
    "            model.add(Conv2D(64, (3,3), strides=1, activation = 'relu', padding='valid'))\n",
    "            #model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "            #<-(11,11)\n",
    "            #model.add(Conv2D(512, (7,7), strides=1, activation = 'relu', padding='same'))\n",
    "            #model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "            model.add(Flatten())\n",
    "            \n",
    "            #Criação da rede Neural.\n",
    "            model.add(Dense(512, activation='relu'))\n",
    "            #model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "            #model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "            #model.add(Dropout(.5))\n",
    "            model.add(Dense(self.action_size, activation='linear'))\n",
    "            model.compile(loss=huber_loss_mean, optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary()\n",
    "        if os.path.isfile(self.weight_backup):\n",
    "            model.load_weights(self.weight_backup)\n",
    "            self.exploration_rate = self.exploration_min\n",
    "            self.load_data()\n",
    "        return model\n",
    "    \n",
    "    def load_data(self):\n",
    "        global data_average_reward, total_reward_game, trainsPerEpisode\n",
    "        if os.path.isdir(diretorioInProcess):\n",
    "            with open(diretorioInProcess+\"avarageProcess.txt\", \"rb\") as avarageDocument:\n",
    "                data_average_reward = pickle.load(avarageDocument)\n",
    "            with open(diretorioInProcess+\"lastRewards.txt\", \"rb\") as lastRewards:\n",
    "                total_reward_game = pickle.load(lastRewards)\n",
    "            with open(diretorioInProcess+\"trainsPerEpisode.txt\", \"rb\") as trainsPerEpisodeDocument:\n",
    "                trainsPerEpisode = pickle.load(trainsPerEpisodeDocument)\n",
    "    \n",
    "            print('LastRewards: {}'.format(total_reward_game))\n",
    "            print('Average: {}'.format(data_average_reward))\n",
    "            \n",
    "            input()\n",
    "    \n",
    "    def save_model(self, avarageList, lastRewards, trainsPerEpisode):   \n",
    "       \n",
    "        if not os.path.isdir(diretorioInProcess):\n",
    "            os.makedirs(diretorioInProcess)\n",
    "            \n",
    "        self.brain.save(self.weight_backup)\n",
    "         \n",
    "        with open(diretorioInProcess+\"avarageProcess.txt\", \"wb\") as avarageDocument:\n",
    "            pickle.dump(avarageList, avarageDocument)\n",
    "            \n",
    "        with open(diretorioInProcess+\"lastRewards.txt\", \"wb\") as lastRewardsDocument:\n",
    "            pickle.dump(lastRewards, lastRewardsDocument)\n",
    "        \n",
    "        with open(diretorioInProcess+\"trainsPerEpisode.txt\", \"wb\") as trainsPerEpisodeDocument:\n",
    "            pickle.dump(trainsPerEpisode, trainsPerEpisodeDocument)\n",
    "        \n",
    "        \n",
    "    def get_last_k_frames(self, state):\n",
    "        frames = np.empty((self.k_frames, self.frame_height, self.frame_width))\n",
    "\n",
    "        for i in range(0, self.k_frames):\n",
    "            _, _, _, n_s, _ = self.memory[len(self.memory)-(self.k_frames-i)]\n",
    "            frames[i] = n_s\n",
    "            \n",
    "        #frames[3] = state  \n",
    "        return np.transpose(frames, axes=(1,2,0))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.exploration_rate or len(self.memory) < self.k_frames+1:\n",
    "            return random.randrange(self.action_size)\n",
    "        \n",
    "        k_frames_state = self.get_last_k_frames(state)\n",
    "        k_frames_state = np.expand_dims(k_frames_state, axis=0)\n",
    "        act_values = self.brain.predict(k_frames_state)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):        \n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    \n",
    "    def pack_K_frames(self, sample_batch_size):\n",
    "        \n",
    "        if len(self.memory) < self.k_frames+2:\n",
    "            return\n",
    "        \n",
    "        state = np.empty((sample_batch_size, self.k_frames, self.frame_height, self.frame_width))\n",
    "        action = np.empty(sample_batch_size, dtype=np.uint8)\n",
    "        reward = np.empty(sample_batch_size, dtype=np.float32)\n",
    "        next_state = np.empty((sample_batch_size, self.k_frames, self.frame_height, self.frame_width))\n",
    "        done = np.empty(sample_batch_size, dtype=np.bool)\n",
    "        \n",
    "        for k in range(sample_batch_size):\n",
    "            index = random.randint(0, len(self.memory)-self.k_frames-2)\n",
    "            for i, idx_memory in enumerate(range(index, index+self.k_frames)):\n",
    "                s, a, r, n_s, d = self.memory[idx_memory]\n",
    "            \n",
    "                state[k][i] = s\n",
    "                next_state[k][i] = n_s\n",
    "                \n",
    "            done[k] = d\n",
    "            action[k] = a\n",
    "            reward[k] = r\n",
    "    \n",
    "        #State = (32,4,84,84)  -> State Transpose = (32,84,84,4) \n",
    "        return np.transpose(state, axes=(0,2,3,1)), action, reward, np.transpose(next_state, axes=(0,2,3,1)), done\n",
    "        \n",
    "\n",
    "    def replay(self, sample_batch_size):\n",
    "       \n",
    "        if len(self.memory) < sample_batch_size:\n",
    "            return\n",
    "        \n",
    "        #sample_batch = random.sample(self.memory, sample_batch_size)\n",
    "        state, action, reward, next_state, done = self.pack_K_frames(sample_batch_size)\n",
    "        \n",
    "        #print('State: {}'.format(state.shape))\n",
    "        #print('Action: {}'.format(action.shape))\n",
    "        #print('Reward: {}'.format(reward.shape))\n",
    "        #print('Next_State: {}'.format(next_state.shape))\n",
    "        #print('Done: {}'.format(done.shape))\n",
    "        #input()\n",
    "        #target = reward\n",
    "        predicted = self.brain_target.predict(next_state) #Previsão proximo estado.\n",
    "        target_f = self.brain.predict(state) #Previsão estado atual.\n",
    "        #print('Predicted: {}'.format(predicted))\n",
    "        #print('Predicted[0]: {}'.format(predicted[2]))\n",
    "        #print('Predicted Max: {}'.format(np.amax(predicted)))\n",
    "        #print('Reward: {}'.format(reward))\n",
    "        #print('Target_f: {}'.format(target_f))\n",
    "        #input()\n",
    "        \n",
    "        for i in range(sample_batch_size):\n",
    "            target = reward[i] + (self.gamma * np.amax(predicted[i]) * (1-done[i]))\n",
    "            target_f[i][action[i]] = target\n",
    "            #print('Action: {}'.format(action[i]))\n",
    "            #print('target: {}'.format(target))\n",
    "            #print('target_f: {}'.format(target_f[i]))\n",
    "            #input()\n",
    "            \n",
    "        \n",
    "        #print('Target_f Formatado: {}'.format(target_f))\n",
    "        #input()\n",
    "        history = self.brain.fit(state, target_f, batch_size=sample_batch_size, epochs=1, verbose=0)\n",
    "            \n",
    "        if self.exploration_rate > self.exploration_min:\n",
    "            self.exploration_rate -= self.exploration_decay\n",
    "    \n",
    "        return history, self.exploration_rate\n",
    "\n",
    "    def update_target_model(self, frame_number):\n",
    "        if (frame_number % UPDATE_TARGET_MODEL == 0 and TRAIN and frame_number > OBSERVER):\n",
    "            self.brain_target.set_weights(self.brain.get_weights())\n",
    "            global qntUpdate\n",
    "            qntUpdate+=1\n",
    "            print('-------------------------UPDATED TARGET MODEL({}) ------------------------------'.format(qntUpdate))\n",
    "\n",
    "\n",
    "class Nintendo():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.env = Server()\n",
    "        self.sample_batch_size = 32\n",
    "        self.episodes = 5000000\n",
    "        self.action_size = 3\n",
    "        self.state_size = (80,80)\n",
    "        self.agent = Agent(self.state_size, self.action_size)\n",
    "        self.number_print = 0\n",
    "        self.best_score = -99999999\n",
    "        self.replay_bestPlay = deque(maxlen=300)\n",
    "        self.crop_on_top = 35 #57\n",
    "        self.crop_on_bottom = 15\n",
    "        self.crop_on_border = 7\n",
    "        self.frame_number=0\n",
    "        self.freq_update=4\n",
    "        self.qnt_train=0\n",
    "        self.epochs_to_save = 50\n",
    "        self.time_train_init = time.time()\n",
    "\n",
    "        self.frames_in_atual_episode=0\n",
    "        self.seconds_in_atual_episode=0\n",
    "    \n",
    "    def actions(self,n):\n",
    "        if n > 5:\n",
    "            print('Numero maior que quantidade de buttões')\n",
    "            return\n",
    "        return ['left', 'right', 'A'][n]\n",
    "    \n",
    "    def restart_chronometer(self):\n",
    "        self.frames_in_atual_episode=0\n",
    "        self.seconds_in_atual_episode=0\n",
    "    \n",
    "    def get_frames_per_seconds_in_atual_episode(self):\n",
    "        return int(self.frames_in_atual_episode / (time.time() - self.seconds_in_atual_episode))\n",
    "    \n",
    "    def to_gray_scale(self, img):\n",
    "        return 0.299*img[:,:,0] + 0.587*img[:,:,1] + 0.114*img[:,:,2]\n",
    "    \n",
    "    def down_sample(self, img):\n",
    "        return img[::2,::2]\n",
    "    \n",
    "    def preprocess_img(self, img):        \n",
    "        new_image = cv2.resize(np.asarray(img, dtype=np.float32)/ 255, self.state_size, interpolation=cv2.INTER_AREA)\n",
    "        '''plt.imshow(new_image)\n",
    "        plt.show()\n",
    "        print('Shape: {}'.format(new_image.shape))\n",
    "        input()'''\n",
    "        return new_image\n",
    "        \n",
    "    def crop_img(self, img):\n",
    "        #return img[self.crop_on_top: -self.crop_on_bottom, self.crop_on_border:-self.crop_on_border]\n",
    "        return img[35:195, 8:-8]\n",
    "  \n",
    "    def transform_reward(self, reward):\n",
    "        return np.sign(reward)\n",
    "      \n",
    "    def formatTimeBr(time):\n",
    "        horas = time/3600\n",
    "        minutos = (time%3600)/60\n",
    "        segundos = (time%3600)%60\n",
    "        \n",
    "        return str('{}hr : {}min : {}seg'.format(horas, minutos, segundos))\n",
    "    \n",
    "    def save_image_epoch(self, gif_to_save, epoch, r):\n",
    "        \n",
    "        if (r == 1):\n",
    "            diretorio = diretorioInProcess+'/movies/'\n",
    "            if not os.path.isdir(diretorio):\n",
    "                os.makedirs(diretorio)\n",
    "                \n",
    "            frames_per_seconds_gif = 60\n",
    "            seconds = len(gif_to_save)/frames_per_seconds_gif\n",
    "    \n",
    "            imageio.mimwrite(diretorio+str(epoch)+'.mp4', gif_to_save , fps = 75)\n",
    "            print('Gif Salvo') \n",
    "            \n",
    "    def run(self):\n",
    "        global total_reward_game, data_average_reward, trainsPerEpisode\n",
    "    \n",
    "        try:\n",
    "            for i_episodes in range(self.episodes):\n",
    "                js = self.env.reset('unnecessary',grayscale=True, downsample=2, min_y=45, max_y=230)\n",
    "                state = js['matriz']\n",
    "               \n",
    "                state = self.preprocess_img(state)\n",
    "                \n",
    "                done = False\n",
    "                atual_epoch = []\n",
    "                total_reward=0\n",
    "                history_list = []\n",
    "                exploration = 1.0\n",
    "                self.seconds_in_atual_episode= time.time()\n",
    "                last_reward = 0\n",
    "                \n",
    "                while not done:\n",
    "                                        \n",
    "                    #if i_episodes > 600 or not TRAIN:\n",
    "                    #self.env.render()\n",
    "                    action = self.agent.act(state)\n",
    "                    js = self.env.step(self.actions(action), grayscale=True, downsample=2, min_y=45, max_y=230)\n",
    "                    next_state = js['matriz']\n",
    "                    if js['reward'] > last_reward:\n",
    "                        reward = 1\n",
    "                    elif js['reward'] == last_reward:\n",
    "                        reward = 0\n",
    "                    else:\n",
    "                        reward = -1\n",
    "                    last_reward = js['reward']\n",
    "                    done = True if js['endgame'] != 8 else False\n",
    "                    \n",
    "                    total_reward+=reward\n",
    "                    #self.replay_bestPlay.append(next_state)\n",
    "                    #if total_reward >= 5:\n",
    "                    #    self.smile_for_the_photo()\n",
    "                    #if (i_episodes % self.epochs_to_save == 0):\n",
    "                    #    atual_epoch.append(np.asarray(next_state))\n",
    "                    next_state = self.preprocess_img(next_state)\n",
    "                    self.agent.remember(state, action, reward, next_state, done)\n",
    "                    state = next_state\n",
    "                    \n",
    "                    self.frame_number+=1\n",
    "                    self.frames_in_atual_episode+=1\n",
    "                    if TRAIN:\n",
    "                        if self.frame_number > OBSERVER and self.frame_number % 4 == 0:\n",
    "                            history, exploration = self.agent.replay(self.sample_batch_size)\n",
    "                            history_list.append(history.history['loss'])    \n",
    "                            self.qnt_train+=1\n",
    "                        \n",
    "                        self.agent.update_target_model(self.frame_number)\n",
    "    \n",
    "                total_reward_game.append(total_reward)\n",
    "                mediaUltimosJogos = np.mean(total_reward_game[-50:])\n",
    "                trainsPerEpisode.append(self.qnt_train)\n",
    "                data_average_reward.append(mediaUltimosJogos)\n",
    "                if TRAIN and self.frame_number > OBSERVER:\n",
    "                    #self.save_image_epoch(atual_epoch, i_episodes, reward)   \n",
    "                    if mediaUltimosJogos > self.best_score and self.frame_number > OBSERVER:\n",
    "                            self.best_score = mediaUltimosJogos\n",
    "                            self.agent.save_model(data_average_reward, total_reward_game, trainsPerEpisode)\n",
    "                            print('Save -> ', end='')\n",
    "                print(\"Episode {}# r: {}# Average: {:.3}# Loss: {:.6} # Train: {} # eps: {:.3}# Space: {}% 'fps: {}:\".format(i_episodes, total_reward, data_average_reward[len(data_average_reward)-1], np.mean(history_list), self.qnt_train, exploration, round(((len(self.agent.memory) / (tamMemoryK*1000)) * 100), 2), self.get_frames_per_seconds_in_atual_episode() ))\n",
    "                self.restart_chronometer()\n",
    "        finally:\n",
    "            plt.plot(trainsPerEpisode, data_average_reward)\n",
    "            plt.xlabel('Trains')\n",
    "            plt.ylabel('Reward')\n",
    "            \n",
    "            #plt.title('Time of train: (Minih) {}'.format(time.time() - self.time_train_init))\n",
    "            #print(self.formatTimeBr((time.time() - s\\elf.time_train_init)))\n",
    "            if TRAIN:\n",
    "                self.agent.save_model(data_average_reward, total_reward_game, trainsPerEpisode)\n",
    "            plt.savefig('atualGraph.png')\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    nintendo = Nintendo()\n",
    "    nintendo.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.asarray(((1,2,3), (3,2,1)), dtype=np.float32)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 4, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "lista = [1,2,3,4,5]\n",
    "lista.reverse()\n",
    "print(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
