{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_server_FCEUX import Server\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting connection from emulator...\n",
      "Connected:  <socket.socket fd=2288, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 12345), raddr=('127.0.0.1', 58640)>\n"
     ]
    }
   ],
   "source": [
    "server = Server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonsMode(string):\n",
    "    a = string.decode()\n",
    "    return json.loads(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapMemory = {\n",
    "    'stateFrame': '0x0001',\n",
    "    'reward': '(0x006D*255) + 0x0086',\n",
    "}\n",
    "server.registerMap(mapMemory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stateFrame': '0x0001', 'reward': '(0x006D*255) + 0x0086'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Get pixeis image.\n",
    "params: {(int) down_sample -> 1, (int) len_max_x -> 255, (int) len_max_y -> 239, (int) len_min_x -> 1,\n",
    "(int) len_min_x -> 1, (bool) grayscale -> False}\n",
    "\n",
    "'''\n",
    "image = server.sendCommandAndReceiveOperation(json.dumps({'operation': 'getScreenShot',\n",
    "          'params': {\n",
    "              'grayscale': True,\n",
    "              'down_sample': 4,\n",
    "              'len_min_y': 45,\n",
    "              'len_max_y': 230\n",
    "          }\n",
    "      }))\n",
    "print('LenImage: {}'.format(len(image)))\n",
    "print(image)\n",
    "#printImage(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = image.decode()\n",
    "b = a.split('json')[1]\n",
    "c = json.loads(b)\n",
    "d = c['matriz']\n",
    "e = np.asarray(d, dtype=np.int16)\n",
    "plt.imshow(e, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dict({'a':2}).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 1 - ['matriz', 'retorno']\n",
      "{'stateFrame': 79, 'reward': 40}\n",
      "I: 2 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 40}\n",
      "I: 3 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 40}\n",
      "I: 4 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 40}\n",
      "I: 5 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 40}\n",
      "I: 6 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 40}\n",
      "I: 7 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 40}\n",
      "I: 8 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 41}\n",
      "I: 9 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 41}\n",
      "I: 10 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 41}\n",
      "I: 11 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 42}\n",
      "I: 12 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 42}\n",
      "I: 13 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 42}\n",
      "I: 14 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 43}\n",
      "I: 15 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 43}\n",
      "I: 16 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 44}\n",
      "I: 17 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 45}\n",
      "I: 18 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 45}\n",
      "I: 19 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 46}\n",
      "I: 20 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 47}\n",
      "I: 21 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 47}\n",
      "I: 22 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 48}\n",
      "I: 23 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 49}\n",
      "I: 24 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 50}\n",
      "I: 25 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 51}\n",
      "I: 26 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 52}\n",
      "I: 27 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 53}\n",
      "I: 28 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 54}\n",
      "I: 29 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 55}\n",
      "I: 30 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 56}\n",
      "I: 31 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 57}\n",
      "I: 32 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 58}\n",
      "I: 33 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 59}\n",
      "I: 34 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 61}\n",
      "I: 35 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 62}\n",
      "I: 36 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 63}\n",
      "I: 37 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 64}\n",
      "I: 38 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 66}\n",
      "I: 39 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 67}\n",
      "I: 40 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 69}\n",
      "I: 41 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 70}\n",
      "I: 42 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 72}\n",
      "I: 43 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 73}\n",
      "I: 44 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 75}\n",
      "I: 45 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 76}\n",
      "I: 46 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 78}\n",
      "I: 47 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 79}\n",
      "I: 48 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 81}\n",
      "I: 49 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 82}\n",
      "I: 50 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 84}\n",
      "I: 51 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 85}\n",
      "I: 52 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 87}\n",
      "I: 53 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 88}\n",
      "I: 54 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 90}\n",
      "I: 55 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 91}\n",
      "I: 56 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 93}\n",
      "I: 57 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 94}\n",
      "I: 58 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 96}\n",
      "I: 59 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 97}\n",
      "I: 60 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 99}\n",
      "I: 61 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 100}\n",
      "I: 62 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 102}\n",
      "I: 63 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 103}\n",
      "I: 64 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 105}\n",
      "I: 65 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 106}\n",
      "I: 66 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 108}\n",
      "I: 67 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 109}\n",
      "I: 68 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 111}\n",
      "I: 69 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 112}\n",
      "I: 70 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 114}\n",
      "I: 71 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 115}\n",
      "I: 72 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 117}\n",
      "I: 73 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 118}\n",
      "I: 74 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 120}\n",
      "I: 75 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 121}\n",
      "I: 76 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 123}\n",
      "I: 77 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 124}\n",
      "I: 78 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 126}\n",
      "I: 79 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 127}\n",
      "I: 80 - ['matriz', 'retorno']\n",
      "{'stateFrame': 4, 'reward': 129}\n",
      "I: 81 - ['matriz', 'retorno']\n",
      "{'stateFrame': 12, 'reward': 130}\n",
      "I: 82 - ['matriz', 'retorno']\n",
      "{'stateFrame': 12, 'reward': 132}\n",
      "I: 83 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 133}\n",
      "I: 84 - ['matriz', 'retorno']\n",
      "{'stateFrame': 4, 'reward': 135}\n",
      "I: 85 - ['matriz', 'retorno']\n",
      "{'stateFrame': 12, 'reward': 136}\n",
      "I: 86 - ['matriz', 'retorno']\n",
      "{'stateFrame': 12, 'reward': 138}\n",
      "I: 87 - ['matriz', 'retorno']\n",
      "{'stateFrame': 252, 'reward': 139}\n",
      "I: 88 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 141}\n",
      "I: 89 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 142}\n",
      "I: 90 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 144}\n",
      "I: 91 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 145}\n",
      "I: 92 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 147}\n",
      "I: 93 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 148}\n",
      "I: 94 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 150}\n",
      "I: 95 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 151}\n",
      "I: 96 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 153}\n",
      "I: 97 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 154}\n",
      "I: 98 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 156}\n",
      "I: 99 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 157}\n",
      "I: 100 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 159}\n",
      "I: 101 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 160}\n",
      "I: 102 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 162}\n",
      "I: 103 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 163}\n",
      "I: 104 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 165}\n",
      "I: 105 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 166}\n",
      "I: 106 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 168}\n",
      "I: 107 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 169}\n",
      "I: 108 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 171}\n",
      "I: 109 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 172}\n",
      "I: 110 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 174}\n",
      "I: 111 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 175}\n",
      "I: 112 - ['matriz', 'retorno']\n",
      "{'stateFrame': 4, 'reward': 177}\n",
      "I: 113 - ['matriz', 'retorno']\n",
      "{'stateFrame': 12, 'reward': 178}\n",
      "I: 114 - ['matriz', 'retorno']\n",
      "{'stateFrame': 12, 'reward': 180}\n",
      "I: 115 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 181}\n",
      "I: 116 - ['matriz', 'retorno']\n",
      "{'stateFrame': 4, 'reward': 183}\n",
      "I: 117 - ['matriz', 'retorno']\n",
      "{'stateFrame': 12, 'reward': 184}\n",
      "I: 118 - ['matriz', 'retorno']\n",
      "{'stateFrame': 12, 'reward': 186}\n",
      "I: 119 - ['matriz', 'retorno']\n",
      "{'stateFrame': 253, 'reward': 187}\n",
      "I: 120 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 189}\n",
      "I: 121 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 190}\n",
      "I: 122 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 192}\n",
      "I: 123 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 193}\n",
      "I: 124 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 195}\n",
      "I: 125 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 196}\n",
      "I: 126 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 198}\n",
      "I: 127 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 199}\n",
      "I: 128 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 201}\n",
      "I: 129 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 202}\n",
      "I: 130 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 204}\n",
      "I: 131 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 205}\n",
      "I: 132 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 207}\n",
      "I: 133 - ['matriz', 'retorno']\n",
      "{'stateFrame': 4, 'reward': 208}\n",
      "I: 134 - ['matriz', 'retorno']\n",
      "{'stateFrame': 12, 'reward': 210}\n",
      "I: 135 - ['matriz', 'retorno']\n",
      "{'stateFrame': 12, 'reward': 211}\n",
      "I: 136 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 213}\n",
      "I: 137 - ['matriz', 'retorno']\n",
      "{'stateFrame': 4, 'reward': 214}\n",
      "I: 138 - ['matriz', 'retorno']\n",
      "{'stateFrame': 12, 'reward': 216}\n",
      "I: 139 - ['matriz', 'retorno']\n",
      "{'stateFrame': 12, 'reward': 217}\n",
      "I: 140 - ['matriz', 'retorno']\n",
      "{'stateFrame': 254, 'reward': 219}\n",
      "I: 141 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 220}\n",
      "I: 142 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 222}\n",
      "I: 143 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 223}\n",
      "I: 144 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 225}\n",
      "I: 145 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 226}\n",
      "I: 146 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 228}\n",
      "I: 147 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 229}\n",
      "I: 148 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 231}\n",
      "I: 149 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 232}\n",
      "I: 150 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 234}\n",
      "I: 151 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 235}\n",
      "I: 152 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 237}\n",
      "I: 153 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 238}\n",
      "I: 154 - ['matriz', 'retorno']\n",
      "{'stateFrame': 4, 'reward': 240}\n",
      "I: 155 - ['matriz', 'retorno']\n",
      "{'stateFrame': 12, 'reward': 241}\n",
      "I: 156 - ['matriz', 'retorno']\n",
      "{'stateFrame': 12, 'reward': 243}\n",
      "I: 157 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 244}\n",
      "I: 158 - ['matriz', 'retorno']\n",
      "{'stateFrame': 4, 'reward': 246}\n",
      "I: 159 - ['matriz', 'retorno']\n",
      "{'stateFrame': 12, 'reward': 247}\n",
      "I: 160 - ['matriz', 'retorno']\n",
      "{'stateFrame': 12, 'reward': 249}\n",
      "I: 161 - ['matriz', 'retorno']\n",
      "{'stateFrame': 255, 'reward': 250}\n",
      "I: 162 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 252}\n",
      "I: 163 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 253}\n",
      "I: 164 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 255}\n",
      "I: 165 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 255}\n",
      "I: 166 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 257}\n",
      "I: 167 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 258}\n",
      "I: 168 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 260}\n",
      "I: 169 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 261}\n",
      "I: 170 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 263}\n",
      "I: 171 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 264}\n",
      "I: 172 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 266}\n",
      "I: 173 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 267}\n",
      "I: 174 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 269}\n",
      "I: 175 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 270}\n",
      "I: 176 - ['matriz', 'retorno']\n",
      "{'stateFrame': 4, 'reward': 272}\n",
      "I: 177 - ['matriz', 'retorno']\n",
      "{'stateFrame': 12, 'reward': 273}\n",
      "I: 178 - ['matriz', 'retorno']\n",
      "{'stateFrame': 12, 'reward': 275}\n",
      "I: 179 - ['matriz', 'retorno']\n",
      "{'stateFrame': 53, 'reward': 276}\n",
      "I: 180 - ['matriz', 'retorno']\n",
      "{'stateFrame': 4, 'reward': 278}\n",
      "I: 181 - ['matriz', 'retorno']\n",
      "{'stateFrame': 12, 'reward': 279}\n",
      "I: 182 - ['matriz', 'retorno']\n",
      "{'stateFrame': 12, 'reward': 281}\n",
      "I: 183 - ['matriz', 'retorno']\n",
      "{'stateFrame': 248, 'reward': 282}\n",
      "I: 184 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 284}\n",
      "I: 185 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 285}\n",
      "I: 186 - ['matriz', 'retorno']\n",
      "{'stateFrame': 57, 'reward': 287}\n",
      "I: 187 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 288}\n",
      "I: 188 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 290}\n",
      "I: 189 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 291}\n",
      "I: 190 - ['matriz', 'retorno']\n",
      "{'stateFrame': 60, 'reward': 293}\n",
      "I: 191 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 192 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 193 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 194 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 195 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 196 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 197 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 198 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 199 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 200 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 201 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 202 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 203 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 204 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 205 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 206 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 207 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 208 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 209 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 210 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 211 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 212 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 213 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 214 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 215 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 216 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 217 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 218 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 219 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 220 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 221 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 222 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 223 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 224 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 225 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 226 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 227 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 228 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 229 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 230 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 231 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 232 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 233 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 234 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 235 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 236 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 237 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 238 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 239 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 240 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 241 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 242 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 243 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 244 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 245 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 246 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 247 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 248 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 249 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 250 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 251 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 252 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 253 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 254 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 255 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 256 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 257 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 258 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 259 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 260 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 261 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 262 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 263 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 264 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 265 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 266 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 267 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 268 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 269 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 270 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 271 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 272 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 273 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 274 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "I: 275 - ['matriz', 'retorno']\n",
      "{'stateFrame': 159, 'reward': 294}\n",
      "Requisitando novamente <class 'ConnectionResetError'>\n",
      "Except: 'NoneType' object is not subscriptable\n",
      "9.102764368057251\n",
      "I: 275\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Press Joypad\n",
    "'''\n",
    "import time\n",
    "import random\n",
    "begin = time.time()\n",
    "images = []\n",
    "i = 0\n",
    "while True:\n",
    "    try:\n",
    "        data = server.step('right', grayscale=True, downsample=2, min_y=45, max_y=230)\n",
    "        #print('Data')\n",
    "        #print(data)\n",
    "        #js = jsonsMode(data)\n",
    "        d = data['matriz']\n",
    "        e = np.asarray(d, dtype=np.int16)\n",
    "        if 'endgame' in data and data['endgame'] != 8:\n",
    "            print('END')\n",
    "            server.reset('Super_Mario_Bros.fc1', grayscale=True, downsample=2, min_y=45, max_y=230)\n",
    "        i+=1\n",
    "        print(\"I: {} - {}\".format(i, list(data.keys())))\n",
    "        print(data['retorno'])\n",
    "    except Exception as e:\n",
    "        print('Except: {}'.format(e))\n",
    "        break\n",
    "    \n",
    "end = time.time()\n",
    "print(end - begin)\n",
    "print('I: {}'.format(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseAction(number):\n",
    "    return ['down', 'left', 'right', 'A', 'B'][number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js = jsonsMode(data)\n",
    "d = js['matriz']\n",
    "e = np.asarray(d, dtype=np.int16)\n",
    "plt.imshow(e, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    op = server.step('right', grayscale=True, downsample=4, min_y=45, max_y=230)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6540\\1242702834.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeque\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Mar 26 10:10:11 2020\n",
    "\n",
    "@author: mateu\n",
    "\"\"\"\n",
    "\n",
    "import gym\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "import imageio\n",
    "from python_server_FCEUX import Server\n",
    "\n",
    "\n",
    "######################################################################################################################################\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as tfback\n",
    "\n",
    "print(\"tf.__version__ is\", tf.__version__)\n",
    "print(\"tf.keras.__version__ is:\", tf.keras.__version__)\n",
    "\n",
    "def _get_available_gpus():\n",
    "    \"\"\"Get a list of available gpu devices (formatted as strings).\n",
    "\n",
    "    # Returns\n",
    "        A list of available GPU devices.\n",
    "    \"\"\"\n",
    "    #global _LOCAL_DEVICES\n",
    "    if tfback._LOCAL_DEVICES is None:\n",
    "        devices = tf.config.list_logical_devices()\n",
    "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
    "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
    "\n",
    "print(_get_available_gpus())\n",
    "tfback._get_available_gpus = _get_available_gpus\n",
    "\n",
    "####VERIFY IF GPU IS RUNNING.\n",
    "#print(device_lib.list_local_devices())\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "import keras\n",
    "\n",
    "import tensorflow.compat.v1 as tf1\n",
    "\n",
    "'''\n",
    "config = tf1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 4} ) \n",
    "sess = tf1.Session(config=config) \n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "'''\n",
    "\n",
    "######################################################################################################################################\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "'''\n",
    " ' Huber loss.\n",
    " ' https://jaromiru.com/2017/05/27/on-using-huber-loss-in-deep-q-learning/\n",
    " ' https://en.wikipedia.org/wiki/Huber_loss\n",
    "'''\n",
    "def huber_loss(y_true, y_pred, clip_delta=1.0):\n",
    "    error = y_true - y_pred\n",
    "    cond  = tf.keras.backend.abs(error) < clip_delta\n",
    "\n",
    "    squared_loss = 0.5 * tf.keras.backend.square(error)\n",
    "    linear_loss  = clip_delta * (tf.keras.backend.abs(error) - 0.5 * clip_delta)\n",
    "\n",
    "    return tf.where(cond, squared_loss, linear_loss)\n",
    "\n",
    "'''\n",
    " ' Same as above but returns the mean loss.\n",
    "'''\n",
    "def huber_loss_mean(y_true, y_pred, clip_delta=1.0):\n",
    "    return tf.keras.backend.mean(huber_loss(y_true, y_pred, clip_delta))\n",
    "\n",
    "score = []\n",
    "\n",
    "TRAIN = True\n",
    "OBSERVER = 100\n",
    "UPDATE_TARGET_MODEL = 1000\n",
    "qntUpdate=0\n",
    "tamMemoryK = 150 # O tamanho da memoria será esse valor multiplicado por 1000.\n",
    "\n",
    "game = 'SuperMarioBross'\n",
    "diretorioInProcess = \"./currentProcessICMinih/\"+game+\"/\"\n",
    "total_reward_game = []\n",
    "data_average_reward = []\n",
    "trainsPerEpisode = []\n",
    "\n",
    "class Agent(): \n",
    "    def __init__(self, state_size, action_size,):\n",
    "        self.weight_backup      = diretorioInProcess+game+\".h5\"\n",
    "        self.state_size         = state_size\n",
    "        self.action_size        = action_size\n",
    "        self.memory             = deque(maxlen=tamMemoryK*1000) if TRAIN else deque(maxlen=5)\n",
    "        self.learning_rate      = 0.0005\n",
    "        self.gamma              = 0.97\n",
    "        self.exploration_rate   = .4\n",
    "        self.exploration_min    = 0.05\n",
    "        self.exploration_decay  = 1.0e-5\n",
    "        self.k_frames           = 4\n",
    "        self.frame_height       = self.state_size[0]\n",
    "        self.frame_width        = self.state_size[1]\n",
    "        self.brain              = self._build_model()\n",
    "        self.brain_target       = self._build_model()\n",
    "\n",
    "\n",
    "    def _build_model(self):\n",
    "        with tf.device('/gpu:0'):\n",
    "            # Neural Net for Deep-Q learning Model\n",
    "            model = Sequential()\n",
    "                \n",
    "            #Criar camada de convolução.\n",
    "            #-> (32,84,84,4)\n",
    "            model.add(Conv2D(32, (8,8), strides=4,  input_shape = (self.state_size[0], self.state_size[1], self.k_frames) , activation = 'relu', padding='valid'))\n",
    "            #<- (84,84)\n",
    "            #->(84,84)\n",
    "            #model.add(MaxPooling2D(pool_size = (2,2), dim_ordering='th'))\n",
    "            #<-(42,42)\n",
    "            #->(42,42)\n",
    "            model.add(Conv2D(64, (4,4), strides=2, activation = 'relu', padding='valid'))\n",
    "            #<-(42,42)\n",
    "            #->(42,42)\n",
    "            #model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "            #<-(21,21)\n",
    "            #->(21,21)\n",
    "            model.add(Conv2D(64, (3,3), strides=1, activation = 'relu', padding='valid'))\n",
    "            #model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "            #<-(11,11)\n",
    "            #model.add(Conv2D(512, (7,7), strides=1, activation = 'relu', padding='same'))\n",
    "            #model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "            model.add(Flatten())\n",
    "            \n",
    "            #Criação da rede Neural.\n",
    "            model.add(Dense(512, activation='relu'))\n",
    "            #model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "            #model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
    "            #model.add(Dropout(.5))\n",
    "            model.add(Dense(self.action_size, activation='linear'))\n",
    "            model.compile(loss=huber_loss_mean, optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary()\n",
    "        if os.path.isfile(self.weight_backup):\n",
    "            model.load_weights(self.weight_backup)\n",
    "            self.exploration_rate = self.exploration_min\n",
    "            self.load_data()\n",
    "        return model\n",
    "    \n",
    "    def load_data(self):\n",
    "        global data_average_reward, total_reward_game, trainsPerEpisode\n",
    "        if os.path.isdir(diretorioInProcess):\n",
    "            with open(diretorioInProcess+\"avarageProcess.txt\", \"rb\") as avarageDocument:\n",
    "                data_average_reward = pickle.load(avarageDocument)\n",
    "            with open(diretorioInProcess+\"lastRewards.txt\", \"rb\") as lastRewards:\n",
    "                total_reward_game = pickle.load(lastRewards)\n",
    "            with open(diretorioInProcess+\"trainsPerEpisode.txt\", \"rb\") as trainsPerEpisodeDocument:\n",
    "                trainsPerEpisode = pickle.load(trainsPerEpisodeDocument)\n",
    "    \n",
    "            print('LastRewards: {}'.format(total_reward_game))\n",
    "            print('Average: {}'.format(data_average_reward))\n",
    "            \n",
    "            input()\n",
    "    \n",
    "    def save_model(self, avarageList, lastRewards, trainsPerEpisode):   \n",
    "       \n",
    "        if not os.path.isdir(diretorioInProcess):\n",
    "            os.makedirs(diretorioInProcess)\n",
    "            \n",
    "        self.brain.save(self.weight_backup)\n",
    "         \n",
    "        with open(diretorioInProcess+\"avarageProcess.txt\", \"wb\") as avarageDocument:\n",
    "            pickle.dump(avarageList, avarageDocument)\n",
    "            \n",
    "        with open(diretorioInProcess+\"lastRewards.txt\", \"wb\") as lastRewardsDocument:\n",
    "            pickle.dump(lastRewards, lastRewardsDocument)\n",
    "        \n",
    "        with open(diretorioInProcess+\"trainsPerEpisode.txt\", \"wb\") as trainsPerEpisodeDocument:\n",
    "            pickle.dump(trainsPerEpisode, trainsPerEpisodeDocument)\n",
    "        \n",
    "        \n",
    "    def get_last_k_frames(self, state):\n",
    "        frames = np.empty((self.k_frames, self.frame_height, self.frame_width))\n",
    "\n",
    "        for i in range(0, self.k_frames):\n",
    "            _, _, _, n_s, _ = self.memory[len(self.memory)-(self.k_frames-i)]\n",
    "            frames[i] = n_s\n",
    "            \n",
    "        #frames[3] = state  \n",
    "        return np.transpose(frames, axes=(1,2,0))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.exploration_rate or len(self.memory) < self.k_frames+1:\n",
    "            return random.randrange(self.action_size)\n",
    "        \n",
    "        k_frames_state = self.get_last_k_frames(state)\n",
    "        k_frames_state = np.expand_dims(k_frames_state, axis=0)\n",
    "        act_values = self.brain.predict(k_frames_state)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):        \n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    \n",
    "    def pack_K_frames(self, sample_batch_size):\n",
    "        \n",
    "        if len(self.memory) < self.k_frames+2:\n",
    "            return\n",
    "        \n",
    "        state = np.empty((sample_batch_size, self.k_frames, self.frame_height, self.frame_width))\n",
    "        action = np.empty(sample_batch_size, dtype=np.uint8)\n",
    "        reward = np.empty(sample_batch_size, dtype=np.float32)\n",
    "        next_state = np.empty((sample_batch_size, self.k_frames, self.frame_height, self.frame_width))\n",
    "        done = np.empty(sample_batch_size, dtype=np.bool)\n",
    "        \n",
    "        for k in range(sample_batch_size):\n",
    "            index = random.randint(0, len(self.memory)-self.k_frames-2)\n",
    "            for i, idx_memory in enumerate(range(index, index+self.k_frames)):\n",
    "                s, a, r, n_s, d = self.memory[idx_memory]\n",
    "            \n",
    "                state[k][i] = s\n",
    "                next_state[k][i] = n_s\n",
    "                \n",
    "            done[k] = d\n",
    "            action[k] = a\n",
    "            reward[k] = r\n",
    "    \n",
    "        #State = (32,4,84,84)  -> State Transpose = (32,84,84,4) \n",
    "        return np.transpose(state, axes=(0,2,3,1)), action, reward, np.transpose(next_state, axes=(0,2,3,1)), done\n",
    "        \n",
    "\n",
    "    def replay(self, sample_batch_size):\n",
    "       \n",
    "        if len(self.memory) < sample_batch_size:\n",
    "            return\n",
    "        \n",
    "        #sample_batch = random.sample(self.memory, sample_batch_size)\n",
    "        state, action, reward, next_state, done = self.pack_K_frames(sample_batch_size)\n",
    "        \n",
    "        #print('State: {}'.format(state.shape))\n",
    "        #print('Action: {}'.format(action.shape))\n",
    "        #print('Reward: {}'.format(reward.shape))\n",
    "        #print('Next_State: {}'.format(next_state.shape))\n",
    "        #print('Done: {}'.format(done.shape))\n",
    "        #input()\n",
    "        #target = reward\n",
    "        predicted = self.brain_target.predict(next_state) #Previsão proximo estado.\n",
    "        target_f = self.brain.predict(state) #Previsão estado atual.\n",
    "        #print('Predicted: {}'.format(predicted))\n",
    "        #print('Predicted[0]: {}'.format(predicted[2]))\n",
    "        #print('Predicted Max: {}'.format(np.amax(predicted)))\n",
    "        #print('Reward: {}'.format(reward))\n",
    "        #print('Target_f: {}'.format(target_f))\n",
    "        #input()\n",
    "        \n",
    "        for i in range(sample_batch_size):\n",
    "            target = reward[i] + (self.gamma * np.amax(predicted[i]) * (1-done[i]))\n",
    "            target_f[i][action[i]] = target\n",
    "            #print('Action: {}'.format(action[i]))\n",
    "            #print('target: {}'.format(target))\n",
    "            #print('target_f: {}'.format(target_f[i]))\n",
    "            #input()\n",
    "            \n",
    "        \n",
    "        #print('Target_f Formatado: {}'.format(target_f))\n",
    "        #input()\n",
    "        history = self.brain.fit(state, target_f, batch_size=sample_batch_size, epochs=1, verbose=0)\n",
    "            \n",
    "        if self.exploration_rate > self.exploration_min:\n",
    "            self.exploration_rate -= self.exploration_decay\n",
    "    \n",
    "        return history, self.exploration_rate\n",
    "\n",
    "    def update_target_model(self, frame_number):\n",
    "        if (frame_number % UPDATE_TARGET_MODEL == 0 and TRAIN and frame_number > OBSERVER):\n",
    "            self.brain_target.set_weights(self.brain.get_weights())\n",
    "            global qntUpdate\n",
    "            qntUpdate+=1\n",
    "            print('-------------------------UPDATED TARGET MODEL({}) ------------------------------'.format(qntUpdate))\n",
    "\n",
    "\n",
    "class Nintendo():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.env = Server()\n",
    "        self.sample_batch_size = 32\n",
    "        self.episodes = 5000000\n",
    "        self.action_size = 3\n",
    "        self.state_size = (80,80)\n",
    "        self.agent = Agent(self.state_size, self.action_size)\n",
    "        self.number_print = 0\n",
    "        self.best_score = -99999999\n",
    "        self.replay_bestPlay = deque(maxlen=300)\n",
    "        self.crop_on_top = 35 #57\n",
    "        self.crop_on_bottom = 15\n",
    "        self.crop_on_border = 7\n",
    "        self.frame_number=0\n",
    "        self.freq_update=4\n",
    "        self.qnt_train=0\n",
    "        self.epochs_to_save = 50\n",
    "        self.time_train_init = time.time()\n",
    "\n",
    "        self.frames_in_atual_episode=0\n",
    "        self.seconds_in_atual_episode=0\n",
    "    \n",
    "    def actions(self,n):\n",
    "        if n > 5:\n",
    "            print('Numero maior que quantidade de buttões')\n",
    "            return\n",
    "        return ['left', 'right', 'A'][n]\n",
    "    \n",
    "    def restart_chronometer(self):\n",
    "        self.frames_in_atual_episode=0\n",
    "        self.seconds_in_atual_episode=0\n",
    "    \n",
    "    def get_frames_per_seconds_in_atual_episode(self):\n",
    "        return int(self.frames_in_atual_episode / (time.time() - self.seconds_in_atual_episode))\n",
    "    \n",
    "    def to_gray_scale(self, img):\n",
    "        return 0.299*img[:,:,0] + 0.587*img[:,:,1] + 0.114*img[:,:,2]\n",
    "    \n",
    "    def down_sample(self, img):\n",
    "        return img[::2,::2]\n",
    "    \n",
    "    def preprocess_img(self, img):        \n",
    "        new_image = cv2.resize(np.asarray(img, dtype=np.float32)/ 255, self.state_size, interpolation=cv2.INTER_AREA)\n",
    "        '''plt.imshow(new_image)\n",
    "        plt.show()\n",
    "        print('Shape: {}'.format(new_image.shape))\n",
    "        input()'''\n",
    "        return new_image\n",
    "        \n",
    "    def crop_img(self, img):\n",
    "        #return img[self.crop_on_top: -self.crop_on_bottom, self.crop_on_border:-self.crop_on_border]\n",
    "        return img[35:195, 8:-8]\n",
    "  \n",
    "    def transform_reward(self, reward):\n",
    "        return np.sign(reward)\n",
    "      \n",
    "    def formatTimeBr(time):\n",
    "        horas = time/3600\n",
    "        minutos = (time%3600)/60\n",
    "        segundos = (time%3600)%60\n",
    "        \n",
    "        return str('{}hr : {}min : {}seg'.format(horas, minutos, segundos))\n",
    "    \n",
    "    def save_image_epoch(self, gif_to_save, epoch, r):\n",
    "        \n",
    "        if (r == 1):\n",
    "            diretorio = diretorioInProcess+'/movies/'\n",
    "            if not os.path.isdir(diretorio):\n",
    "                os.makedirs(diretorio)\n",
    "                \n",
    "            frames_per_seconds_gif = 60\n",
    "            seconds = len(gif_to_save)/frames_per_seconds_gif\n",
    "    \n",
    "            imageio.mimwrite(diretorio+str(epoch)+'.mp4', gif_to_save , fps = 75)\n",
    "            print('Gif Salvo') \n",
    "            \n",
    "    def run(self):\n",
    "        global total_reward_game, data_average_reward, trainsPerEpisode\n",
    "    \n",
    "        try:\n",
    "            for i_episodes in range(self.episodes):\n",
    "                js = self.env.reset('unnecessary',grayscale=True, downsample=2, min_y=45, max_y=230)\n",
    "                state = js['matriz']\n",
    "               \n",
    "                state = self.preprocess_img(state)\n",
    "                \n",
    "                done = False\n",
    "                atual_epoch = []\n",
    "                total_reward=0\n",
    "                history_list = []\n",
    "                exploration = 1.0\n",
    "                self.seconds_in_atual_episode= time.time()\n",
    "                last_reward = 0\n",
    "                \n",
    "                while not done:\n",
    "                                        \n",
    "                    #if i_episodes > 600 or not TRAIN:\n",
    "                    #self.env.render()\n",
    "                    action = self.agent.act(state)\n",
    "                    js = self.env.step(self.actions(action), grayscale=True, downsample=2, min_y=45, max_y=230)\n",
    "                    next_state = js['matriz']\n",
    "                    if js['reward'] > last_reward:\n",
    "                        reward = 1\n",
    "                    elif js['reward'] == last_reward:\n",
    "                        reward = 0\n",
    "                    else:\n",
    "                        reward = -1\n",
    "                    last_reward = js['reward']\n",
    "                    done = True if js['endgame'] != 8 else False\n",
    "                    \n",
    "                    total_reward+=reward\n",
    "                    #self.replay_bestPlay.append(next_state)\n",
    "                    #if total_reward >= 5:\n",
    "                    #    self.smile_for_the_photo()\n",
    "                    #if (i_episodes % self.epochs_to_save == 0):\n",
    "                    #    atual_epoch.append(np.asarray(next_state))\n",
    "                    next_state = self.preprocess_img(next_state)\n",
    "                    self.agent.remember(state, action, reward, next_state, done)\n",
    "                    state = next_state\n",
    "                    \n",
    "                    self.frame_number+=1\n",
    "                    self.frames_in_atual_episode+=1\n",
    "                    if TRAIN:\n",
    "                        if self.frame_number > OBSERVER and self.frame_number % 4 == 0:\n",
    "                            history, exploration = self.agent.replay(self.sample_batch_size)\n",
    "                            history_list.append(history.history['loss'])    \n",
    "                            self.qnt_train+=1\n",
    "                        \n",
    "                        self.agent.update_target_model(self.frame_number)\n",
    "    \n",
    "                total_reward_game.append(total_reward)\n",
    "                mediaUltimosJogos = np.mean(total_reward_game[-50:])\n",
    "                trainsPerEpisode.append(self.qnt_train)\n",
    "                data_average_reward.append(mediaUltimosJogos)\n",
    "                if TRAIN and self.frame_number > OBSERVER:\n",
    "                    #self.save_image_epoch(atual_epoch, i_episodes, reward)   \n",
    "                    if mediaUltimosJogos > self.best_score and self.frame_number > OBSERVER:\n",
    "                            self.best_score = mediaUltimosJogos\n",
    "                            self.agent.save_model(data_average_reward, total_reward_game, trainsPerEpisode)\n",
    "                            print('Save -> ', end='')\n",
    "                print(\"Episode {}# r: {}# Average: {:.3}# Loss: {:.6} # Train: {} # eps: {:.3}# Space: {}% 'fps: {}:\".format(i_episodes, total_reward, data_average_reward[len(data_average_reward)-1], np.mean(history_list), self.qnt_train, exploration, round(((len(self.agent.memory) / (tamMemoryK*1000)) * 100), 2), self.get_frames_per_seconds_in_atual_episode() ))\n",
    "                self.restart_chronometer()\n",
    "        finally:\n",
    "            plt.plot(trainsPerEpisode, data_average_reward)\n",
    "            plt.xlabel('Trains')\n",
    "            plt.ylabel('Reward')\n",
    "            \n",
    "            #plt.title('Time of train: (Minih) {}'.format(time.time() - self.time_train_init))\n",
    "            #print(self.formatTimeBr((time.time() - s\\elf.time_train_init)))\n",
    "            if TRAIN:\n",
    "                self.agent.save_model(data_average_reward, total_reward_game, trainsPerEpisode)\n",
    "            plt.savefig('atualGraph.png')\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    nintendo = Nintendo()\n",
    "    nintendo.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.asarray(((1,2,3), (3,2,1)), dtype=np.float32)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = [1,2,3,4,5]\n",
    "lista.reverse()\n",
    "print(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
